License: CC BY-NC-ND 4.0
arXiv:2510.23972v1 [cs.LG] 28 Oct 2025
‚Ä†
An efficient probabilistic hardware architecture for diffusion-like models
Andra≈æ Jelinƒçiƒç
Owen Lockwood
Akhil Garlapati
Guillaume Verdon
Trevor McCourt‚àó,
trevor@extropic.ai
Extropic Corporation
(October 28, 2025)
Abstract
The proliferation of probabilistic AI has promoted proposals for specialized stochastic computers. Despite promising efficiency gains, these proposals have failed to gain traction because they rely on fundamentally limited modeling techniques and exotic, unscalable hardware. In this work, we address these shortcomings by proposing an all-transistor probabilistic computer that implements powerful denoising models at the hardware level. A system-level analysis indicates that devices based on our architecture could achieve performance parity with GPUs on a simple image benchmark using approximately 10,000 times less energy.
The unprecedented recent investment in large-scale AI systems will soon put a strain on the world‚Äôs energy infrastructure. Every year, U.S. firms spend an amount larger than the inflation-adjusted cost of the Apollo program on AI-focused data centers [17, 65]. By 2030, these data centers could consume 10% of all of the energy produced in the U.S. [4].
Despite this enormous bet on scaling today‚Äôs AI systems, they may be far from optimal in terms of energy efficiency. Existing AI systems based on autoregressive large language models (LLMs) are valuable tools in white-collar fields [45, 41, 50, 51, 12, 52], and are being adopted by consumers faster than the internet [8]. However, LLMs were architected specifically for GPUs [68], hardware originally intended for graphics, whose suitability for machine learning was discovered accidentally decades later [18, 15].
Figure 1:Leveraging CMOS probabilistic hardware in ultra-efficient AI systems. The central result of this article: an all‚Äëtransistor probabilistic computer running a denoising thermodynamic model (DTM) could match GPU performance on a simple modeling benchmark while using about 10,000√ó less energy. All models are trained on binarized Fashion-MNIST [72] and evaluated with Fr√©chet Inception Distance (FID) [32]. DTM variants are of increasing depth, chaining 2‚Äì8 sequential Energy-Based Models (EBMs). GPU baselines cover single‚Äëstep VAE [42] and GAN [31], plus DDPM [62] at varying numbers of steps. We also compare DTM to a monolithic EBM across multiple mixing‚Äëtime limits. The horizontal axis shows the energy needed for generating a single new image using the trained model (inference).
Had a different style of hardware been popular in the last few decades, AI algorithms would have evolved in a completely different direction, and possibly a more energy-efficient one. This interplay between algorithm research and hardware availability is known as the "Hardware Lottery" [37], and it entrenches hardware-algorithm pairings that may be far from optimal.
Therefore, prudent planning calls for systematic exploration of other types of AI systems in search of energy-efficient alternatives. Active efforts include mixed‚Äësignal compute‚Äëin‚Äëmemory accelerators [5], photonic neural networks [7], and neuromorphic processors that emulate biological spiking [30, 59].
The development of more efficient computers for AI is challenging because it requires innovation not only at the component level but also at the system level. It is insufficient to invent a new technology that performs a mathematical operation efficiently in isolation; one must also know how to combine multiple components to run a practical algorithm. In addition to these integration challenges, GPU performance per joule is doubling every few years [66], making it very difficult for cutting-edge computing schemes to gain mainstream adoption.
Probabilistic computing is an attractive approach because it can connect directly to AI at the system level via Energy-Based Models (EBMs). EBMs are a well-established model class in contemporary deep learning and have been competitive with the state of the art in tasks like image generation and robotic path planning [63, 39].
Hardware implementations of EBMs work with special model families that adhere to physical constraints such as locality, sparsity, and connection density. Thanks to these constraints, probabilistic computers can utilize specialized stochastic circuitry to efficiently and quickly produce samples from a Boltzmann distribution [61]. Depending on the precise kind of hardware being used, this sampling may occur as part of the natural dynamics of the device [53, 70, 3, 67, 25] or may be orchestrated using an algorithm like Gibbs sampling [49, 10, 60, 57]. Using probabilistic hardware to accelerate EBMs falls under the broad umbrella of thermodynamic computing [19].
Past attempts at EBM accelerators have suffered from issues at both the architectural and hardware levels. All previous proposals used EBMs as monolithic models of data distributions, which is known to be challenging to scale [23]. Additionally, existing devices have relied on exotic components such as magnetic tunnel junctions as sources of intense thermal noise for random-number generation (RNG) [44, 38, 60]. These exotic components have not yet been tightly integrated with transistors in commercial CMOS processes and do not currently constitute a scalable solution [2, 1, 22].
In this work, we address these issues and propose a commercially viable probabilistic computing system. Our contributions extend from broad architectural choices down to designing and fabricating novel mixed-signal RNG circuitry.
At the top level, we introduce a new probabilistic computer architecture that runs Denoising Thermodynamic Models (DTMs) instead of monolithic EBMs. As their name suggests, rather than using the hardware‚Äôs EBM to model data distributions directly, DTMs sequentially compose many hardware EBMs to model a process that denoises the data gradually. Diffusion models [62, 35] also follow this denoising procedure and are much more capable than EBMs. This key architectural change addresses a fundamental issue with previous approaches and represents the first scalable method for applying probabilistic hardware to machine learning.
Additionally, we show that our new architecture can be implemented at scale using present-day CMOS processes by experimentally demonstrating an all-transistor RNG that is fast, energy efficient, and small. By using transistors as the only building blocks of our RNG circuits, we avoid the significant and ambiguous communication overheads that can occur at interfaces between technologies. Furthermore, the absence of such communication overhead allows for the principled forecasting of device performance that we present in this work. Our RNG leverages the stochastic dynamics of subthreshold transistor networks, which we have recently studied in detail in Ref. [26].
Our system-level analysis indicates that combining our new architecture with our all-transistor probabilistic computing circuitry could achieve unprecedented energy efficiency in probabilistic modeling. Figure 1 compares the predicted performance and energy consumption of such a system to several standard deep-learning algorithms running on GPUs and a traditional EBM-based probabilistic computer. The DTM-based probabilistic computer system achieves performance parity with the most efficient GPU-based algorithm while using around four orders of magnitude less energy.
The remainder of this article will substantiate the results presented in Fig. 1, which are based on a combination of measurements from real circuits, physical models, and simulations. To begin, we introduce a fundamental compromise inherent in using EBMs as standalone models of data, which we refer to as the mixing-expressivity tradeoff. We then discuss how this compromise can be avoided by wielding EBMs as part of a denoising process rather than monolithically. Next, we outline how to build a hardware system using DTMs to implement this denoising process at a very low level. Then, we study simulations of this hardware system, further justifying the results shown in Fig. 1 and highlighting some of the practical merits of DTMs compared to existing approaches. Finally, we conclude by discussing how the capabilities of probabilistic accelerators for machine learning may be scaled by merging them with traditional neural networks.
IThe Challenge with EBMs
The fundamental problem of machine learning is inferring the probability distribution that underlies some data [40, 28]. An early approach [33] to this was to use a monolithic EBM (MEBM) to fit a data distribution directly by shaping a parameterized energy function ‚Ñ∞:


P‚Äã(x;Œ∏)‚àùe‚àí‚Ñ∞‚Äã(x,Œ∏),


(1)

where x is a random variable representing the data and Œ∏ represents the parameters of the EBM.
Fitting an MEBM corresponds to assigning low energies to values of x where data are abundant and high energies to values of x that are far from data. Real-world data are often clustered into distinct modes [20, 9], meaning that a MEBM that fits data well will have a complex, rugged energy landscape with many deep valleys surrounded by tall mountains. This complexity is illustrated by the cartoon in Fig. 2 (a).
Unlike the systems we propose, existing probabilistic computers based on MEBMs struggle with the multimodality of real-world data, which hinders their efficiency. Namely, the amount of energy the computer must expend to draw a sample from the MEBM‚Äôs distribution can be tremendous if its energy landscape is very rough.
Specifically, sampling algorithms that operate in high dimensions (such as Gibbs sampling [48]) are locally-informed iterative procedures, meaning that they sample a landscape by randomly making small movements in the space based on low-dimensional information. When using such a procedure to sample from Eq. (1), the probability that the iteration will move up in energy to some state X‚Äã[k+1] is exponentially small in the energy increase compared to the current state X‚Äã[k], i.e.,


‚Ñô‚Äã(X‚Äã[k+1]=x‚Ä≤|X‚Äã[k]=x)‚àùe‚àí(‚Ñ∞‚Äã(x‚Ä≤)‚àí‚Ñ∞‚Äã(x)).


(2)

For large differences in energy, like those encountered when trying to move between two valleys separated by a significant barrier, this probability can be very close to zero. These barriers grind the iterative sampler to a halt.
The mixing-expressivity tradeoff (MET) summarizes this issue with existing probabilistic computer architectures, reflecting the fact that modeling performance and sampling hardness are coupled for MEBMs. Specifically, as the expressivity (modeling performance) of an MEBM increases, its mixing time (the amount of computational effort needed to draw independent samples from the MEBM‚Äôs distribution) becomes progressively longer, resulting in expensive inference and unstable training [13, 21].
The empirical effect of the MET on the efficiency of MEBM-based probabilistic computing systems is illustrated in Fig. 2 (b). Mixing time increases very rapidly with performance, inflating the amount of energy required to sample from the model. The effect of this increased mixing time is reflected in Fig. 1: despite the MEBM-based solution using the same EBMs and underlying hardware as the DTM-based solution, its energy consumption is several orders of magnitude larger due to the glacially slow mixing.
Figure 2:The mixing-expressivity tradeoff. (a) A cartoon illustrating the mixing-expressivity tradeoff in EBMs. It shows a projection of an energy landscape fit to a simple dataset. The "airplane" mode is well separated from the "dog" mode, with very little data in between. Progressively better fits of the EBM to the data tend to feature larger energy barriers Œî‚ÄãE between the modes, making the EBM increasingly difficult to sample from. (b) An example of the effect of the mixing-expressivity tradeoff on model performance as measured using the Fashion-MNIST dataset. The blue curve in the plot shows the results of experiments on MEBMs with limited allowed mixing time. Performance and mixing time are strongly correlated. Mixing times were computed by fitting an exponential function to the large-lag behavior of the autocorrelation function; see Appendix K. In contrast, a DTM (orange cross) has higher performance despite substantially lower sampling requirements.
IIDenoising thermodynamic models
The MET makes it clear that MEBMs have a flaw that makes them challenging and energetically costly to scale. However, this flaw is avoidable, and many types of probabilistic machine learning models have been developed to solve the distribution modeling problem while circumventing the MET.
Denoising diffusion models were explicitly designed to sidestep the MET by gradually building complexity through a series of simple, easy-to-sample probabilistic transformations [62]. By doing so, they allowed for much more complex distributions to be expressed given a fixed compute budget and substantially expanded the capabilities of generative models [36, 54, 56].
DTMs merge EBMs with diffusion models, offering an alternative path for probabilistic computing that assuages the MET. DTMs are a slight generalization of recent work from deep learning practitioners that has pushed the frontier of EBM performance [27, 74, 73, 75].
Instead of trying to use a single EBM to model the data, DTMs chain many EBMs to gradually build up to the complexity of the data distribution. This gradual buildup of complexity allows the landscape of each EBM in the chain to remain relatively simple (and easy to sample) without limiting the complexity of the distribution modeled by the chain as a whole; see Fig. 2 (b).
Denoising models attempt to reverse a process that gradually transforms the data distribution Q‚Äã(x0) into simple noise. This forward process is given by the Markov chain


Q‚Äã(x0,‚Ä¶,xT)=Q‚Äã(x0)‚Äã‚àèt=1TQ‚Äã(xt|xt‚àí1).


(3)

The forward process is typically chosen such that it has a unique stationary distribution Q‚Äã(xT), which takes a simple form (e.g., Gaussian or uniform).
Reversal of the forward process is achieved by learning a set of distributions PŒ∏‚Äã(xt‚àí1|xt) that approximate the reversal of each conditional in Eq. (3). In doing so, we learn a map from simple noise to the data distribution, which can then be used to generate new data.
In traditional diffusion models, the forward process is made to be sufficiently fine-grained (using a large number of steps T) such that the conditional distribution of each step in the reverse process takes some simple form (such as Gaussian or categorical). This simple distribution is parameterized by a neural network, which is then trained to minimize the Kullback-Leibler (KL) divergence between the joint distributions Q and PŒ∏,


‚ÑíD‚ÄãN(Œ∏)=D(Q(x0,‚Ä¶,xT)‚à•PŒ∏(x0,‚Ä¶,xT)),


(4)

where the joint distribution of the model is the product of the learned conditionals:


PŒ∏‚Äã(x0,‚Ä¶,xT)=Q‚Äã(xT)‚Äã‚àèt=1TPŒ∏‚Äã(xt‚àí1|xt).


(5)

See Appendix A.A.2 for more details.
EBM-based denoising models approach the problem from a different angle [27]. In many cases, it is straightforward to re-cast the forward process in an exponential form,


Q‚Äã(xt|xt‚àí1)‚àùe‚àí‚Ñ∞t‚àí1f‚Äã(xt‚àí1,xt),


(6)

where ‚Ñ∞t‚àí1f is the energy function associated with the forward process step that adds noise to xt‚àí1. We then use an EBM with a particular energy function to model the conditional, i.e.,


PŒ∏‚Äã(xt‚àí1|xt)‚àùe‚àí(‚Ñ∞t‚àí1f‚Äã(xt‚àí1,xt)+‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,Œ∏)).


(7)

Equation (7) allows for a compromise between the number of steps in the approximation to the reverse process and the difficulty of sampling at each step. As the number of steps in the forward process is increased, the effect of each noising step becomes smaller, meaning that ‚Ñ∞t‚àí1f more tightly binds xt to xt‚àí1. This binding can simplify the distribution given in Eq. (7) by imposing an energy penalty that prevents it from being strongly multimodal; see Appendix A.A.4 for further discussion.
As illustrated in Fig. 3 (a), models of the form given in Eq. (7) reshape simple noise into an approximation of the data distribution. Increasing T while holding the EBM architecture constant simultaneously increases the expressive power of the chain and makes each step easier to sample from, entirely bypassing the MET.
To maximally leverage probabilistic hardware for EBM sampling, DTMs generalize Eq. (7) by introducing latent variables {zt}:


PŒ∏‚Äã(xt‚àí1|xt)‚àù‚àëzt‚àí1e‚àí(‚Ñ∞t‚àí1f‚Äã(xt‚àí1,xt)+‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,zt‚àí1,Œ∏)).


(8)

Introducing latent variables allows the size and complexity of the probabilistic model to be increased independently of the data dimension.
A convenient property of DTMs is that if the approximation to the reverse-process conditional is exact (PŒ∏‚Äã(xt‚àí1|xt)‚ÜíQ‚Äã(xt‚àí1|xt)), one also learns the marginal distribution at t‚àí1,


Q‚Äã(xt‚àí1)‚àù‚àëzt‚àí1e‚àí‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,zt‚àí1,Œ∏).


(9)

See Appendix A.A.6 for further details. Note that this property relies on the normalizing constant associated with the distribution in Eq. (6) being independent of xt‚àí1.
Figure 3:The denoising thermodynamic computer architecture. (a) Traditional diffusion models have simple conditionals and must take small steps when approximating the reverse process. Since EBMs can express more complex distributions, DTMs can take potentially much larger steps. (b) A sketch of how a chip based on the DTCA chains hardware EBMs to approximate the reverse process. Each EBM is implemented by distinct circuitry, parts of which are dedicated to receiving the inputs and conditionally sampling the outputs and latents. (c) An abstract diagram of a hardware EBM. The state variables xt and xt‚àí1 map onto distinct physical degrees of freedom represented by the blue and green nodes, respectively. The coupling between these two sets of nodes implements the forward process energy function ‚Ñ∞tf‚Äã(xt‚àí1,xt). The set of orange nodes represents a set of latent variables zt‚àí1. The couplings between these nodes and to the xt‚àí1 nodes implements ‚Ñ∞t‚àí1Œ∏‚Äã(zt‚àí1,xt‚àí1).
IIIDenoising Thermodynamic Computers
The Denoising Thermodynamic Computer Architecture (DTCA) tightly integrates DTMs into probabilistic hardware, allowing for the highly efficient implementation of EBM-aided diffusion models.
Practical implementations of the DTCA utilize natural-to-implement EBMs that exhibit sparse and local connectivity, as is typical in the literature [49]. This constraint allows sampling of the EBM to be performed by massively parallel arrays of primitive circuitry that implement Gibbs sampling. Refer to Appendices B and C for a further theoretical discussion of the hardware architecture.
A key feature of the DTCA is that ‚Ñ∞t‚àí1f can be implemented efficiently using our constrained EBMs. Specifically, for both continuous and discrete diffusion, ‚Ñ∞t‚àí1f can be implemented using a single pairwise interaction between corresponding variables in xt and xt‚àí1; see Appendix A.A.1 and C.C.1 for details. This structure can be reflected in how the chip is laid out to implement these interactions without violating locality constraints.
Critically, Eq. (8) places no constraints on the form of ‚Ñ∞t‚àí1Œ∏. Therefore, we are free to use EBMs that our hardware implements especially efficiently. At the lowest level, this corresponds to high-dimensional, regularly structured latent variable EBM. If more powerful models are desired, these hardware latent-variable EBMs can be arbitrarily scaled by combining them into software-defined graphical models.
The modular nature of DTMs enables various hardware implementations. For example, each EBM in the chain can be implemented using distinct physical circuitry on the same chip, as shown in Fig. 3 (b). Alternatively, the various EBMs may be split across several communicating chips or implemented by the same hardware, reprogrammed with distinct sets of weights at different times. For any given EBM in the chain, both the data variables xt, xt‚àí1 and the latent variables zt‚àí1 are physically embodied in sampling circuits that are connected in a simple way that reflects the structure of Eq. (7). This variable structure is shown schematically in Fig. 3 (c).
To understand the performance of a future hardware device, we developed a GPU simulator of the DTCA and used it to train a DTM on the Fashion-MNIST dataset. We measure the performance of the DTM using FID and utilize a physical model to estimate the energy required to generate new images. These numbers can be compared to conventional algorithm/hardware pairings, such as a VAE running on a GPU; these results are shown in Fig. 1.
The DTM that produced the results shown in Fig. 1 used Boltzmann machine EBMs. Boltzmann machines, also known as Ising models in physics, use binary random variables and are the simplest type of discrete-variable EBM.
Boltzmann machines are hardware efficient because the Gibbs sampling update rule required to sample from them is simple. Boltzmann machines implement energy functions of the form


‚Ñ∞‚Äã(x)=‚àíŒ≤‚Äã(‚àëi‚â†jxi‚ÄãJi‚Äãj‚Äãxj+‚àëi=1hi‚Äãxi),


(10)

where each xi‚àà{‚àí1,1}. The Gibbs sampling update rule for sampling from the corresponding EBM is


‚Ñô‚Äã(Xi‚Äã[k+1]=+1‚à£X‚Äã[k]=x)=œÉ‚Äã(2‚ÄãŒ≤‚Äã(‚àëj‚â†iJi‚Äãj‚Äãxj+hi)),


(11)

which can be evaluated simply using an appropriately biased source of random bits.
Figure 4:A programmable source of random bits. (a) A laboratory measurement of the operating characteristic of our RNG. The probability of the output voltage signal being in the high state (x=1) can be programmed by varying an input voltage. The relationship between ‚Ñô‚Äã(x=1) and the input voltage is well-approximated by a sigmoid function. The inset shows the output voltage signal as a function of time for different input voltages. (b) The autocorrelation function of the RNG at the unbiased point (‚Ñô‚Äã(x=1)=0.5). The decay is approximately exponential with the rate œÑ0‚âà100‚Äãns. (c) Estimating the effect of manufacturing variation on RNG performance. Each point in the plot represents the results of a simulation of an RNG circuit with transistor parameters sampled according to a procedure defined by the manufacturer‚Äôs PDK. Each color represents a different process corner, each for which ‚àº200 realizations of the RNG were simulated. The "typical" corner represents a balanced case, whereas the other two are asymmetric corners where the two types of transistors (NMOS and PMOS) are skewed in opposite directions. The slow NMOS and fast PMOS case is worst performing for us due to an asymmetry in our design.
Implementing our proposed hardware architecture using Boltzmann machines is particularly simple. A device will consist of a regular grid of Bernoulli sampling circuits, where each sampling circuit implements the Gibbs sampling update for a single variable xi. The bias of the sampling circuits (probability that it produces 1 as opposed to ‚àí1) is constrained to be a sigmoidal function of an input voltage, allowing the conditional update given in Eq. (11) to be implemented using a simple circuit that adds currents such as a resistor network (See Appendix D.D.1).
Specifically, the EBMs employed in this work were sparse, deep Boltzmann machines comprising L√óL grids of binary variables, where L=70 was used in most cases. Each variable was connected to several (in most cases, 12) of its neighbors following a simple pattern. At random, some of the variables were selected to represent the data xt‚àí1, and the rest were assigned to the latent variables zt‚àí1. Then, an extra node was connected to each data node to implement the coupling to xt. See Appendix C for further details on the Boltzmann machine architecture.
Due to our chosen connectivity patterns, our Boltzmann machines are bipartite (two-colorable). Since each color block can be sampled in parallel, a single iteration of Gibbs sampling corresponds to sampling the first color block conditioned on the second and then vice versa. Starting from some random initialization, this block sampling procedure could then be repeated for K iterations (where K is longer than the mixing time of the sampler, typically K‚âà1000) to draw samples from Eq. (7) for each step in the approximation to the reverse process.
To enable a near-term, large-scale realization of the DTCA, we leveraged the shot-noise dynamics of subthreshold transistors [26] to build an RNG that is fast, energy-efficient, and small. Our all-transistor RNG is programmable and has the desired sigmoidal response to a control voltage, as shown by experimental measurements in Fig. 4 (a). The stochastic voltage signal output from the RNG has an approximately exponential autocorrelation function that decays in around 100 ns, as illustrated in Fig. 4 (b). As shown in Ref. [26], this time constraint is much larger than the lower limit imposed by the correlation time of the noise in our transistors. The RNG could, therefore, be made much faster via an improved design. Appendix J provides further details about our RNG.
A practical advantage to our all-transistor RNG is that detailed and proven foundry-provided models can be used to study the effect of manufacturing variations on our circuit design. In Fig. 4 (c), we use this process development kit (PDK) to study the speed and energy consumption of our RNG as a function of both systematic inter-wafer skews to the transistor parameters (process corners) and the expected variation within a single chip. We find that the RNG works reliably despite these non-idealities, meaning it can readily be scaled to the massive grids required by the DTCA.
The energy estimates given in Fig. 1 for the probabilistic computer were constructed using a physical model of an all-transistor Boltzmann machine Gibbs sampler. The dominant contributions to this model are captured by the formula


E=T‚ÄãKmix‚ÄãL2‚ÄãEcell,


(12)




Ecell=Erng+Ebias+Eclock+Ecomm,


(13)

where Erng comes from the data in Fig. 4 (c). The term Ebias is estimated using a physical model of a possible biasing circuit, and Eclock and Ecomm are derived from physical reasoning about the costs of the clock and inter-cell communications respectively. Kmix is the number of sampling iterations required to satisfactorily mix the chain for inference, which is generally less than the number of iterations used during training. Kmix=250 was used for the DTM (See Appendix D.D.4), while the mixing time measured in Fig. 2 was used for the MEBM.
This model is approximate, but it captures the underlying physics of a real device and provides a reasonable order-of-magnitude estimate of the actual energy consumption. Generally, given the same transistor process we used for our RNG and some reasonable selections for other free parameters of the model, we can estimate Ecell‚âà2‚ÄãfJ. See Appendix D for an exhaustive derivation of this model.
We use a simple model for the energy consumption of the GPU that underestimates the actual values. We compute the total number of floating-point operations (FLOPs) required to generate a sample from the trained model and divide that by the FLOP/joule specification given by the manufacturer. See Appendix E for further discussion.
Figure 5:Detailed results on the Fashion-MNIST dataset. (a) Images generated by a denoising model. Here, to achieve better-looking images, several binary variables were combined to represent a single grayscale pixel. The noisiness of the grayscale levels is an artifact of our embedding method; see Appendix G. (b) An experiment showing how DTMs are more stable to train than MEBMs. Complementing DTMs with the ACP completely stabilizes training. For the DTMs, the maximum ry‚Äãy‚Äã[K] value over all the layers is shown. (c) The effect of scaling EBM complexity on DTM performance. The grid size L was modified to change the number of latent variables compared to the (fixed) number of data variables. Generally, EBM layers with more connectivity and longer allowed mixing times can utilize more latent variables and, therefore, achieve higher performance.
IVTraining DTMs
The EBMs used in the experiments presented in Fig. 1 were trained by applying the standard Monte-Carlo estimator for the gradients of EBMs [64] to Eq. (4), which yields


‚àáŒ∏‚ÑíD‚ÄãN(Œ∏)=‚àët=1TùîºQ‚Äã(xt‚àí1,xt)[ùîºPŒ∏‚Äã(zt‚àí1|xt‚àí1,xt)‚Äã[‚àáŒ∏‚Ñ∞t‚àí1m]‚àíùîºPŒ∏‚Äã(xt‚àí1,zt‚àí1|xt)[‚àáŒ∏‚Ñ∞t‚àí1m]].


(14)

Notably, each term in the sum over t can be computed independently. To estimate either term in Eq. (14), first, sample tuples (xt‚àí1,xt) from the forward process Q‚Äã(xt‚àí1,xt). Then, for each of these tuples, clamp the reverse process EBM to the sampled values appropriately and use a time average over K iterations of Gibbs sampling to estimate the inner expectation value. Averaging the result over the tuples yields the desired gradient estimate.
It should be noted that the DTCA allows our EBMs to have finite and short mixing times, which enables sufficient sampling iterations to be used to achieve nearly unbiased estimates of the gradient. Unbiased gradient estimates are not possible for MEBMs in most cases due to their long mixing times [14].
A well-trained denoising model generates new examples that resemble the training data by incrementally pulling them out of noise; the outputs of an 8-step denoising model trained on the Fashion-MNIST dataset are shown in Fig. 5 (a). At the final time T, the images are random bits. Structure begins to emerge as the chain progresses, ultimately resulting in clean images at time t=0.
DTMs alleviate the training instability that is fundamental to MEBMs. The parameters of MEBMs are usually initialized using a strategy that results in an easy-to-sample-from energy landscape [34]. For this reason, in the early stages of training, sampling from Eq. (1) is possible, and the gradient estimates produced using Eq. (14) are unbiased. However, as these gradients are followed, the MEBM is reshaped according to the data distribution and begins to become complex and multimodal. This induced multimodality greatly increases the sampling complexity of the distribution, causing samples to deviate from equilibrium. Gradients computed using non-equilibrium samples do not necessarily point in a meaningful direction, which can halt or, in some cases, even reverse the training process.
This instability in MEBMs leads to unpredictable training dynamics that can be sensitive to implementation details. An example of the training dynamics for several different types of models is shown in Fig. 5 (b). The top plot displays the quality of images generated during training, while the bottom plot shows a measure of the sampler‚Äôs mixing. Image quality is measured using the FID metric, and mixing quality is measured using the normalized autocorrelation


ry‚Äãy‚Äã[k]=ùîº‚Äã[(y‚Äã[j]‚àíŒº)‚Äã(y‚Äã[j+k]‚àíŒº)]ùîº‚Äã[(y‚Äã[j]‚àíŒº)2],


(15)




Œº=ùîº‚Äã(y‚Äã[j]),


(16)

where k is the delay time; y‚Äã[j] is some low dimensional projection of the sampling chain data at iteration j, y‚Äã[j]=f‚Äã(x‚Äã[j]); and ùîº‚Äã[‚ãÖ] indicates expectation values taken over independent Gibbs sampling chains. The lower plot in Fig. 5 (b) shows the autocorrelation at a delay equal to the total number of sampling iterations used to estimate the gradients during training. Generally, if ry‚Äãy is close to 1, gradients were estimated using far-from-equilibrium samples and were likely of low quality. If it is close to zero, the samples should be close to equilibrium and produce high-quality gradient estimates. See Appendix H for further discussion.
The destabilizing effect of non-equilibrium sampling is apparent from the blue curves in Fig. 5 (b). At the beginning of training, both quality and ry‚Äãy increase, indicating that the multimodality of the data is being imprinted on the model. Then ry‚Äãy becomes so large that the quality of the gradient starts to decline, resulting in a plateau and, ultimately, a degradation of the model‚Äôs quality.
Denoising alone significantly stabilizes training. Because the transformation carried out by each layer is simpler, the distribution that the model must learn is less complex and, therefore, easier to sample from. The orange curve in Fig. 5 (b) shows the training dynamics for a typical denoising model. The autocorrelation and performance remain good for much longer than the MEBM.
As training progresses, the DTM eventually becomes unstable, which can be attributed to the development of a complex energy landscape among the latent variables. To combat this, we modify the training procedure to penalize models that mix poorly. We add a term to the loss function that nudges the optimization towards a distribution that is easy to sample from, i.e.,


‚ÑítT‚ÄãC=ùîºQ‚Äã(xt)[D(‚àèi=1MPŒ∏(sit‚àí1|xt)‚à•PŒ∏(st‚àí1|xt))],


(17)

where st‚àí1=(xt‚àí1,zt‚àí1) and xit‚àí1 indicates the ith of the M variables in xt‚àí1. This term penalizes the distance between the learned conditional distribution and a factorized distribution with identical marginals and is a form of total correlation penalty [16].
The total loss function is the sum of Eq. (4) and this total correlation penalty:


‚Ñí=‚ÑíD‚ÄãN+‚àët=1TŒªt‚Äã‚ÑítT‚ÄãC.


(18)

The parameters Œªt control the relative strength of the total correlation penalty for each step in the reverse process.
We use an Adaptive Correlation Penalty (ACP) to set the Œªt as large as necessary to keep sampling tractable for each layer. During training, we periodically measure the autocorrelations of each learned conditional at a delay equal to the number of sampling iterations used during gradient estimation. If the autocorrelation for the jth layer is close to zero, Œªj is decreased, and vice-versa.
Our closed-loop control of the correlation penalty strengths is crucial, allowing us to maximize the expressivity of the EBMs while maintaining stable training. The green curves in Fig. 5 (b) show an example of training dynamics under this closed-loop control policy. Model quality increases monotonically, and the autocorrelation stays small throughout training. This closed-loop control of the correlation penalty was employed during the training of most models used to produce the results in this article, including those shown in Fig. 1.
Generally, the performance of DTMs improves as their size increases. As shown in Fig. 1, increasing the depth of the DTM from 2 to 8 substantially improves the quality of generated images. As shown in Fig. 5 (c), increasing the width, degree, and allowed mixing time of the EBMs in the chain also generally improves performance.
However, some subtleties prevent this specific EBM topology from being scaled indefinitely. The top plot in Fig. 5 (c) shows that scaling the number of latent variables (with fixed allowed mixing time) only improves performance if the connectivity of the graph is also scaled; otherwise, performance can decrease. This dependence makes sense, as increasing the number of latent variables in this way increases the depth of the Boltzmann machine, which is known to make sampling more difficult. Beyond a certain point, increasing the model‚Äôs ability to express complex energy landscapes may render it unable to learn, given the allowed mixing time of K‚âà1000. This same effect is shown in the bottom plot of Fig. 5 (c), which demonstrates that larger values of K are required to support wider models holding connectivity constant.
In general, it would be naive to expect that a hardware-efficient EBM topology can be scaled in isolation to model arbitrarily complex datasets. For example, there is no good reason for which a connectivity pattern that is convenient from a wire-routing perspective would also be well suited to represent the correlation structure of a complex real-world dataset.
VConclusion: Scaling Thermodynamic Machine Learning
The core doctrine of modern machine learning is the relentless scaling of models as a means of solving ever-harder problems. Models that utilize probabilistic computers may be similarly scaled to enhance their capabilities beyond the relatively simple dataset considered in this work so far.
However, we hypothesize that the correct way to scale probabilistic machine learning hardware systems is not in isolation but rather as a component in a larger hybrid thermodynamic-deterministic machine learning (HTDML) system. Such a hybrid system integrates probabilistic hardware with more traditional machine learning accelerators.
A hybrid approach is sensible because there is no a priori reason to believe that a probabilistic computer should handle every part of a machine learning problem, and sometimes a deterministic processor is likely a better tool for the job.
The goal of HTDML is to design practical machine learning systems that minimize the energy used to achieve desired modeling fidelity on a particular task. This efficiency will be achieved through a cross-disciplinary effort that eschews the software/hardware abstraction barrier to design computers that respect physical constraints.
Mathematically, the landscape of HTDML may be summarized as


Etot‚Äã(S,D,p)=Edet‚Äã(S,D,p)+Eprob‚Äã(S,D,p),


(19)

where Etot is the total energy consumed by some machine learning system S to evaluate a model of some dataset D with performance p. Etot decomposes into an energy term that comes from the deterministic computer Edet and a term that comes from the probabilistic computer Eprob.
Only the extremes of HTDML have been explored thus far. The existing body of work on machine learning has Etot=Edet and the early demonstrations in this work have Etot=Eprob. Like many engineered systems, optimal solutions will be found somewhere in the middle, where the contributions from the various subsystems are nearly balanced [6, 69, 47].
System designs between the extremes represent completely unexplored territory. Many foundational problems in HTDML still need to be solved.
For example, more rigorous methods of embedding data into hardware EBMs will need to be developed to go beyond the relatively simple datasets considered here. Indeed, binarization is not viable in general, and embedding into richer types of variables (such as categorical) at the probabilistic hardware level is not particularly efficient or principled.
One way to solve the embedding problem is to use a small neural network to map data into the probabilistic hardware. A naive experiment demonstrating this is shown in Fig. 6. Here, we train a small neural network to embed the CIFAR-10 dataset [43] into a binary DTM. The embedding network was trained using an autoencoder loss to binarize the data, which was then used to train a DTM. The decoder of the embedding network was then trained further using a GAN objective to increase the quality of the generated images. This training procedure is described in further detail in Appendix I.
Despite the overhead of the embedding neural network, this primitive hybrid model is efficient. As shown in the figure, the generator of the traditional GAN has to be roughly 10 times larger than the decoder of our embedding network to match the performance of the hybrid model.
Figure 6:Embedding data into a DTM using a neural network. Here, we show the results of using a simple embedding model in combination with a DTM. The DTM is trained to generate CIFAR-10 images and achieves performance parity with a traditional GAN using a ‚àº10√ó smaller deterministic neural network.
The embedding procedure employed in Fig. 6 will likely be significantly improved through further study. One major flaw with our method is that the autoencoder and DTM are not jointly trained, which means that the embedding learned by the autoencoder may not be well-suited to the way information can flow in the DTM, given its limited connectivity. The problem of using a denoising chain of EBMs in latent space has been studied in the deep learning literature, and some of this work may be leveraged to solve the embedding problem discussed here [74].
The models used in this article are small compared to what could be implemented using even an early probabilistic computer based on the DTCA. Based on the size of our RNG, it can be estimated that ‚àº106 sampling cells could be fit into a 6√ó6‚Äã¬µm chip (see Appendix J). In contrast, the largest DTM shown in Fig. 1 would use only around 50,000 cells.
Given this gap between the size of our models and the capabilities of a potential hardware device, a natural question to study is how these probabilistic models can be scaled outside the obvious approaches considered here. This scaling likely corresponds to developing architectures that fuse multiple EBMs to implement each step in the reverse process. One possible approach is to construct software-defined graphical models of EBMs that enable non-local information routing, which could alleviate some of the issues associated with a fixed and local interaction structure.
One difficulty with HTDML research is that simulating large hardware EBMs on GPUs can be a challenging task. GPUs run these EBMs much less efficiently than probabilistic computers and the sparse data structures that naturally arise when working with hardware EBMs do not mesh well with regular tensor data types. We have both short and long-term solutions to these challenges.
To address these challenges in the short term, we have open-sourced a software library [24] that enables XLA-accelerated [55] simulation of hardware EBMs. This library is written in JAX [11] and automates the complex slicing operations that enable hardware EBM sampling. We also provide additional code that wraps this library to implement the specific experiments presented in this article [29]. In the longer term, the realization of large-scale probabilistic computers, such as the one proposed in this article, using advanced transistor processes [58, 71, 46] will significantly alleviate the challenges associated with HTDML research and accelerate the pace of progress.
References
[1]
M. A. Abeed and S. Bandyopadhyay (2020)Sensitivity of the Power Spectra of Thermal Magnetization Fluctuations in Low Barrier Nanomagnets Proposed for Stochastic Computing to In-Plane Barrier Height Variations and Structural Defects.SPIN 10 (01), pp. 2050001.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[2]
Md. A. Abeed and S. Bandyopadhyay (2019)Low Energy Barrier Nanomagnet Design for Binary Stochastic Neurons: Design Challenges for Real Nanomagnets With Fabrication Defects.IEEE Magn. Lett. 10 (), pp. 1‚Äì5.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[3]
S. H. Adachi and M. P. Henderson (2015)Application of Quantum Annealing to Training of Deep Neural Networks.External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[4]
J. Aljbour, T. Wilson, and P. Patel (2024)Powering Intelligence: Analyzing Artificial Intelligence and Data Center Energy Consumption.EPRI White Paper no. 3002028905.External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[5]
S. Ambrogio, P. Narayanan, A. Okazaki, A. Fasoli, C. Mackin, K. Hosokawa, A. Nomura, T. Yasuda, A. Chen, A. Friz, et al. (2023)An analog-AI chip for energy-efficient speech recognition and transcription.Nature 620 (7975), pp. 768‚Äì775.External Links: DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[6]
G. M. Amdahl (1967)Validity of the single processor approach to achieving large scale computing capabilities.In Proceedings of the April 18-20, 1967, spring joint computer conference,pp. 483‚Äì485.External Links: Document, LinkCited by: ¬ßV.
[7]
S. Bandyopadhyay, A. Sludds, S. Krastanov, R. Hamerly, N. Harris, D. Bunandar, M. Streshinsky, M. Hochberg, and D. Englund (2024)Single-chip photonic deep neural network with forward-only training.Nat. Photon. 18 (12), pp. 1335‚Äì1343.External Links: DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[8]
A. Bick, A. Blandin, and D. J. Deming (2024)The rapid adoption of generative ai.Technical reportNational Bureau of Economic Research.External Links: DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[9]
C. M. Bishop (1994)Mixture density networks.External Links: LinkCited by: ¬ßI.
[10]
W. A. Borders, A. Z. Pervaiz, S. Fukami, K. Y. Camsari, H. Ohno, and S. Datta (2019)Integer factorization using stochastic magnetic tunnel junctions.Nature 573 (7774), pp. 390‚Äì393.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[11]
J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke, J. VanderPlas, S. Wanderman-Milne, and Q. Zhang (2018)JAX: composable transformations of Python+NumPy programs.External Links: LinkCited by: ¬ßV.
[12]
E. Brynjolfsson, D. Li, and L. Raymond (2025)Generative AI at work.Q. J. Econ..External Links: DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[13]
D. Carbone, M. Hua, S. Coste, and E. Vanden-Eijnden (2023)Efficient training of energy-based models using Jarzynski equality.Adv. Neural Inf. Process. Syst. 36, pp. 52583‚Äì52614.External Links: Document, LinkCited by: ¬ßI.
[14]
M. A. Carreira-Perpinan and G. Hinton (2005)On contrastive divergence learning.In International workshop on artificial intelligence and statistics,pp. 33‚Äì40.Cited by: ¬ßIV.
[15]
K. Chellapilla, S. Puri, and P. Simard (2006-10)High Performance Convolutional Neural Networks for Document Processing.In Tenth International Workshop on Frontiers in Handwriting Recognition, G. Lorette (Ed.),La Baule (France).External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[16]
R. T. Chen, X. Li, R. B. Grosse, and D. K. Duvenaud (2018)Isolating sources of disentanglement in variational autoencoders.Adv. Neural Inf. Process. Syst. 31.External Links: LinkCited by: ¬ßIV.
[17]
A. A. Chien (2023-07)GenAI: Giga$$$, TeraWatt-Hours, and GigaTons of CO2.Commun. ACM 66 (8), pp. 5.External Links: ISSN 0001-0782, Link, DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[18]
A. Coates, B. Huval, T. Wang, D. J. Wu, A. Y. Ng, and B. Catanzaro (2013)Deep learning with cots hpc systems.In Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28,ICML‚Äô13, pp. III‚Äì1337‚ÄìIII‚Äì1345.External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[19]
T. Conte, E. DeBenedictis, N. Ganesh, T. Hylton, J. P. Strachan, R. S. Williams, A. Alemi, L. Altenberg, G. Crooks, J. Crutchfield, et al. (2019)Thermodynamic computing.arXiv [cs.CY].External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[20]
A. P. Dempster, N. M. Laird, and D. B. Rubin (1977)Maximum likelihood from incomplete data via the EM algorithm.J. R. Stat. Soc. Ser. B (Methodol.) 39 (1), pp. 1‚Äì22.External Links: Document, LinkCited by: ¬ßI.
[21]
G. Desjardins, A. Courville, Y. Bengio, P. Vincent, O. Delalleau, et al. (2010)Parallel tempering for training of restricted Boltzmann machines.In Proceedings of the thirteenth international conference on artificial intelligence and statistics,pp. 145‚Äì152.External Links: LinkCited by: ¬ßI.
[22]
J. L. Drobitch and S. Bandyopadhyay (2019)Reliability and Scalability of p-Bits Implemented With Low Energy Barrier Nanomagnets.IEEE Magn. Lett. 10 (), pp. 1‚Äì4.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[23]
Y. Du and I. Mordatch (2019)Implicit generation and modeling with energy based models.In Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch√©-Buc, E. Fox, and R. Garnett (Eds.),Vol. 32, pp. .External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[24]
Extropic (2025)thrml: Thermodynamic Hypergraphical Model Library.External Links: LinkCited by: ¬ßV.
[25]
R. Faria, K. Y. Camsari, and S. Datta (2017)Low-Barrier Nanomagnets as p-Bits for Spin Logic.IEEE Magn. Lett. 8 (), pp. 1‚Äì5.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[26]
N. Freitas, G. Massarelli, J. Rothschild, D. Keane, E. Dawe, S. Hwang, A. Garlapati, and T. McCourt (2025)Taming non-equilibrium thermal fluctuations in subthreshold CMOS circuits.Phys. Rev. Lett..Note: SubmittedCited by: ¬ßIII, An efficient probabilistic hardware architecture for diffusion-like models.
[27]
R. Gao, Y. Song, B. Poole, Y. N. Wu, and D. P. Kingma (2021)Learning Energy-Based Models by Diffusion Recovery Likelihood.arXiv [cs.LG].External Links: LinkCited by: ¬ßII, ¬ßII.
[28]
Z. Ghahramani (2015)Probabilistic machine learning and artificial intelligence.Nature 521 (7553), pp. 452‚Äì459.External Links: DocumentCited by: ¬ßI.
[29]
github.com/pschilliOrange/dtm-replication.External Links: LinkCited by: ¬ßV.
[30]
H. A. Gonzalez, J. Huang, F. Kelber, K. K. Nazeer, T. Langer, C. Liu, M. Lohrmann, A. Rostami, M. Schone, B. Vogginger, et al. (2024)SpiNNaker2: A large-scale neuromorphic system for event-based and asynchronous machine learning.arXiv [cs.ET].External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[31]
I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio (2014)Generative adversarial nets.In Advances in Neural Information Processing Systems, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger (Eds.),Vol. 27, pp. .External Links: LinkCited by: Figure 1.
[32]
M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter (2017)GANs trained by a two time-scale update rule converge to a local nash equilibrium.In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.),Vol. 30, pp. .External Links: LinkCited by: Figure 1.
[33]
G.E. Hinton (1984)Boltzmann Machines: Constraint Satisfaction Networks that Learn.Carnegie-Mellon University. Department of Computer Science, Carnegie-Mellon University, Department of Computer Science.External Links: LinkCited by: ¬ßI.
[34]
G. E. Hinton (2012)A practical guide to training restricted Boltzmann machines.In Neural Networks: Tricks of the Trade: Second Edition,pp. 599‚Äì619.Cited by: ¬ßIV.
[35]
J. Ho, A. Jain, and P. Abbeel (2020)Denoising Diffusion Probabilistic Models.In Advances in Neural Information Processing Systems,Vol. 33, pp. 6840‚Äì6851.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[36]
J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans (2022)Cascaded diffusion models for high fidelity image generation.J. Mach. Learn. Res. 23 (47), pp. 1‚Äì33.External Links: Document, LinkCited by: ¬ßII.
[37]
S. Hooker (2021-11)The hardware lottery.Commun. ACM 64 (12), pp. 58‚Äì65.External Links: ISSN 0001-0782, Link, DocumentCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[38]
M. Horodynski, C. Roques-Carmes, Y. Salamin, S. Choi, J. Sloan, D. Luo, and M. Soljaƒçiƒá (2025)Stochastic logic in biased coupled photonic probabilistic bits.Commun. Phys. 8 (1), pp. 31.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[39]
M. Janner, Y. Du, J. Tenenbaum, and S. Levine (2022)Planning with Diffusion for Flexible Behavior Synthesis.In International Conference on Machine Learning,pp. 9902‚Äì9915.External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[40]
M. I. Jordan and T. M. Mitchell (2015)Machine learning: Trends, perspectives, and prospects.Science 349 (6245), pp. 255‚Äì260.External Links: Document, LinkCited by: ¬ßI.
[41]
D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo (2024)GPT-4 passes the bar exam.Philos. Trans. R. Soc. A 382 (2270), pp. 20230254.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[42]
D. P. Kingma and M. Welling (2022)Auto-Encoding Variational Bayes.External Links: LinkCited by: Figure 1.
[43]
A. Krizhevsky and G. Hinton (2009)Learning multiple layers of features from tiny images.Technical reportTechnical Report 0, Technical report, University of Toronto, University of Toronto, Toronto, Ontario.External Links: LinkCited by: ¬ßV.
[44]
W. Lee, H. Kim, H. Jung, Y. Choi, J. Jeon, and C. Kim (2025)Correlation free large-scale probabilistic computing using a true-random chaotic oscillator p-bit.Sci. Rep. 15 (1), pp. 8018.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[45]
Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. D. Lago, T. Hubert, P. Choy, C. de Masson d‚ÄôAutume, I. Babuschkin, X. Chen, P. Huang, J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, D. J. Mankowitz, E. S. Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu, and O. Vinyals (2022)Competition-level code generation with AlphaCode.Science 378 (6624), pp. 1092‚Äì1097.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[46]
J.C. Liu, S. Mukhopadhyay, A. Kundu, S.H. Chen, H.C. Wang, D.S. Huang, J.H. Lee, M.I. Wang, R. Lu, S.S. Lin, Y.M. Chen, H.L. Shang, P.W. Wang, H.C. Lin, G. Yeap, and J. He (2020)A Reliability Enhanced 5nm CMOS Technology Featuring 5th Generation FinFET with Fully-Developed EUV and High Mobility Channel for Mobile SoC and High Performance Computing Application.In 2020 IEEE International Electron Devices Meeting (IEDM),Vol. , pp. 9.2.1‚Äì9.2.4.External Links: Document, LinkCited by: ¬ßV.
[47]
D. M. Markovic (2006-05)A power/area optimal approach to vlsi signal processing.Ph.D. Thesis, EECS Department, University of California, Berkeley.External Links: LinkCited by: ¬ßV.
[48]
K. P. Murphy (2023)Probabilistic Machine Learning: Advanced Topics.MIT Press.External Links: LinkCited by: ¬ßI.
[49]
S. Niazi, S. Chowdhury, N. A. Aadit, M. Mohseni, Y. Qin, and K. Y. Camsari (2024)Training deep Boltzmann networks with sparse Ising machines.Nat. Electron. 7 (7), pp. 610‚Äì619.External Links: Document, LinkCited by: ¬ßIII, An efficient probabilistic hardware architecture for diffusion-like models.
[50]
H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz (2023)Capabilities of gpt-4 on medical challenge problems.arXiv [cs.CL].External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[51]
S. Noy and W. Zhang (2023)Experimental evidence on the productivity effects of generative artificial intelligence.Science 381 (6654), pp. 187‚Äì192.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[52]
S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer (2023)The impact of ai on developer productivity: Evidence from github copilot.arXiv [cs.SE].External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[53]
C. Pratt, K. Ray, and J. Crutchfield (2023-07)Dynamical Computing on the Nanoscale: Superconducting Circuits for Thermodynamically-Efficient Classical Information Processing.External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[54]
R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer (2022)High-resolution image synthesis with latent diffusion models.In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,pp. 10684‚Äì10695.External Links: Document, LinkCited by: ¬ßII.
[55]
A. Sabne (2020)XLA : Compiling Machine Learning for Peak Performance.Cited by: ¬ßV.
[56]
C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. L. Denton, K. Ghasemipour, R. Gontijo Lopes, B. Karagol Ayan, T. Salimans, J. Ho, D. J. Fleet, and M. Norouzi (2022)Photorealistic text-to-image diffusion models with deep language understanding.In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.),Vol. 35, pp. 36479‚Äì36494.External Links: LinkCited by: ¬ßII.
[57]
M. M. H. Sajeeb, N. A. Aadit, S. Chowdhury, T. Wu, C. Smith, D. Chinmay, A. Raut, K. Y. Camsari, C. Delacour, and T. Srimani (2025-07)Scalable connectivity for ising machines: dense to sparse.Phys. Rev. Appl. 24, pp. 014005.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[58]
T. Sekigawa and Y. Hayashi (1984)Calculated threshold-voltage characteristics of an XMOS transistor having an additional bottom gate.Solid-State Electron. 27 (8-9), pp. 827‚Äì828.External Links: Document, LinkCited by: ¬ßV.
[59]
S. B. Shrestha, J. Timcheck, P. Frady, L. Campos-Macias, and M. Davies (2024)Efficient Video and Audio Processing with Loihi 2.In ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),Vol. , pp. 13481‚Äì13485.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[60]
N. S. Singh, K. Kobayashi, Q. Cao, K. Selcuk, T. Hu, S. Niazi, N. A. Aadit, S. Kanai, H. Ohno, S. Fukami, et al. (2024)CMOS plus stochastic nanomagnets enabling heterogeneous computers for probabilistic inference and learning.Nat. Commun. 15 (1), pp. 2685.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models, An efficient probabilistic hardware architecture for diffusion-like models.
[61]
N. S. Singh, K. Kobayashi, Q. Cao, K. Selcuk, T. Hu, S. Niazi, N. A. Aadit, S. Kanai, H. Ohno, S. Fukami, et al. (2024)CMOS plus stochastic nanomagnets enabling heterogeneous computers for probabilistic inference and learning.Nat. Commun. 15 (1), pp. 2685.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[62]
J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli (2015-07‚Äì09 Jul)Deep Unsupervised Learning using Nonequilibrium Thermodynamics.In Proceedings of the 32nd International Conference on Machine Learning, F. Bach and D. Blei (Eds.),Proceedings of Machine Learning Research, Vol. 37, Lille, France, pp. 2256‚Äì2265.External Links: LinkCited by: Figure 1, ¬ßII, An efficient probabilistic hardware architecture for diffusion-like models.
[63]
Y. Song and S. Ermon (2019)Generative modeling by estimating gradients of the data distribution.In Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch√©-Buc, E. Fox, and R. Garnett (Eds.),Vol. 32, pp. .External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[64]
Y. Song and D. P. Kingma (2021)How to train your energy-based models.arXiv [cs.LG].External Links: LinkCited by: ¬ßIV.
[65]
D. D. Stine (2009-06)The manhattan project, the apollo program, and federal energy technology r&d programs: a comparative analysis.ReportTechnical Report RL34645, Congressional Research Service, Washington, D.C..Cited by: An efficient probabilistic hardware architecture for diffusion-like models.
[66]
Y. Sun, N. B. Agostini, S. Dong, and D. Kaeli (2019)Summarizing CPU and GPU design trends with product data.arXiv [cs.DC].External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[67]
B. Sutton, K. Y. Camsari, B. Behin-Aein, and S. Datta (2017)Intrinsic optimization using stochastic nanomagnets.Sci. Rep. 7 (1), pp. 44370.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[68]
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ≈Å. Kaiser, and I. Polosukhin (2017)Attention is all you need.In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.),Vol. 30, pp. .External Links: LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[69]
S. Williams, A. Waterman, and D. Patterson (2009-04)Roofline: an insightful visual performance model for multicore architectures.Commun. ACM 52 (4), pp. 65‚Äì76.External Links: ISSN 0001-0782, Link, DocumentCited by: ¬ßV.
[70]
G. Wimsatt, O. Saira, A. B. Boyd, M. H. Matheny, S. Han, M. L. Roukes, and J. P. Crutchfield (2021-08)Harnessing fluctuations in thermodynamic computing via time-reversal symmetries.Phys. Rev. Res. 3, pp. 033115.External Links: Document, LinkCited by: An efficient probabilistic hardware architecture for diffusion-like models.
[71]
S. Wu, C. Chang, M. Chiang, C. Lin, J. Liaw, J. Cheng, J. Yeh, H. Chen, S. Chang, K. Lai, et al. (2022)A 3nm CMOS FinFlex‚Ñ¢ platform technology with enhanced power efficiency and performance for mobile SoC and high performance computing applications.In 2022 International Electron Devices Meeting (IEDM),pp. 27‚Äì5.External Links: Document, LinkCited by: ¬ßV.
[72]
H. Xiao, K. Rasul, and R. Vollgraf (2017)Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.arXiv [cs.LG].External Links: LinkCited by: Figure 1.
[73]
M. Xu, T. Geffner, K. Kreis, W. Nie, Y. Xu, J. Leskovec, S. Ermon, and A. Vahdat (2024)Energy-based diffusion language models for text generation.arXiv [cs.CL].External Links: LinkCited by: ¬ßII.
[74]
P. Yu, S. Xie, X. Ma, B. Jia, B. Pang, R. Gao, Y. Zhu, S. Zhu, and Y. N. Wu (2022)Latent Diffusion Energy-Based Model for Interpretable Text Modelling.In International Conference on Machine Learning,pp. 25702‚Äì25720.External Links: LinkCited by: ¬ßII, ¬ßV.
[75]
Y. Zhu, J. Xie, Y. N. Wu, and R. Gao (2021)Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood.In The Twelfth International Conference on Learning Representations,External Links: LinkCited by: ¬ßII.
Appendix ADenoising Diffusion Models
Denoising diffusion models try to learn to time-reverse a random process that converts data into simple noise. Here, we will review some details on how these models work to support the analysis in the main text.
A.1Forward Processes
The forward process is a random process that is used to convert the data distribution into noise. This conversion into noise is achieved through a stochastic differential equation in the continuous-variable case and a Markov jump process in the discrete case.
A.1.1Continuous Variables
In the continuous case, the typical choice of forward process is the It√¥ diffusion,


d‚ÄãX‚Äã(t)=‚àíX‚Äã(t)‚Äãd‚Äãt+2‚ÄãœÉ‚Äãd‚ÄãW


(20)

where X‚Äã(t) is a length N vector representing the state variable at time t, œÉ is a constant, and d‚ÄãW is a length N vector of independent Wiener processes.
The transition kernel for a random process defines how the probability distribution evolves in time,


Qt|0‚Äã(x‚Ä≤|x)=‚Ñô‚Äã(X‚Äã(t)=x‚Ä≤|X‚Äã(0)=x)


(21)

For the case of Eq. (20) the transition kernel is,


Qt+s|s‚Äã(x‚Ä≤|x)‚àùe‚àí12‚Äã(x‚Ä≤‚àíŒº)T‚ÄãŒ£‚àí1‚Äã(x‚Ä≤‚àíŒº)


(22)




Œº=e‚àít‚Äãx


(23)




Œ£=œÉ2‚ÄãI‚Äã(1‚àíe‚àí2‚Äãt)


(24)

this solution can be verified by direct substitution into the corresponding Fokker-Planck equation. In the limit of infinite time, Œº‚Üí0 and Œ£‚ÜíœÉ2‚ÄãI. Therefore, the stationary distribution of this process is zero-mean Gaussian noise with a standard deviation of œÉ.
A.1.2Discrete Variables
The stochastic dynamics of some discrete variable X may be described by the Markov jump process,


d‚ÄãQtd‚Äãt=‚Ñí‚ÄãQt


(25)

where ‚Ñí is the generator of the dynamics, which is an M√óM matrix that stores the transition rates between the various states. Qt is a length M vector that assigns a probability to each possible state X may take at time t.
The transition rate from the ith state to the jth state is given by the matrix element ‚Ñí‚Äã[j,i], which here takes the particular form,


‚Ñí‚Äã[j,i]=Œ≥‚Äã(‚àí(M‚àí1)‚ÄãŒ¥j,i+(1‚àíŒ¥j,i))


(26)

where Œ¥ is used to indicate the Kronecker delta function. Eq. (26) describes a random process where the probability per unit time to jump between any two states is Œ≥.
Since Eq. (25) is linear, the dynamics of Qt can be understood entirely via the eigenvalues and eigenvectors of ‚Ñí,


‚Ñí‚Äãvk=Œªk‚Äãvk


(27)

Note that by symmetry of ‚Ñí, we do not distinguish between right and left eigenvectors.
One eigenvector-eigenvalue pair (v0,Œª0=0) corresponds to the unique stationary state of ‚Ñí, with all entries of v0 being equal to some constant (if normalized, then v0‚Äã[j]=1M for all j). The long-time dynamics of this MJP transform any initial distribution to a uniform distribution over all states.
The remaining eigenvectors are decaying modes associated with negative eigenvalues. These additional M‚àí1 eigenvectors take the form,


vj‚Äã[i]=‚àíŒ¥i,0+Œ¥i,j


(28)




Œªj=‚àíŒ≥‚ÄãM


(29)

where Eq. (28) and Eq. (29) are valid for j‚àà[1,M‚àí1]. Therefore, all solutions to this MJP decay exponentially to the uniform distribution with rate Œ≥‚ÄãM.
The time-evolution of Q is given by the matrix exponential,


Qt=e‚Ñí‚Äãt‚ÄãQ0.


(30)

This matrix exponential is evaluated by diagonalizing ‚Ñí,


e‚Ñí‚Äãt=P‚ÄãeD‚Äãt‚ÄãP‚àí1


(31)

where the columns of P are the M eigenvectors vk and D is a diagonal matrix of the eigenvalues Œªk.
Using the solution for the eigenvalues and eigenvectors found above, we can solve for the matrix elements of e‚Ñí‚Äãt,


e‚Ñí‚Äãt‚Äã[j,i]=Œ¥i,j‚Äã(1+(M‚àí1)‚Äãe‚àíŒ≥‚ÄãM‚ÄãtM)+(1‚àíŒ¥i,j)‚Äã(1‚àíe‚àíŒ≥‚ÄãM‚ÄãtM)


(32)

Using this solution, we can deduce an exponential form for the matrix elements of e‚Ñí‚Äãt,


e‚Ñí‚Äãt‚Äã[j,i]=1Z‚Äã(t)‚ÄãeŒì‚Äã(t)‚ÄãŒ¥i,j


(33)




Œì‚Äã(t)=ln‚Å°(1+(M‚àí1)‚Äãe‚àíŒ≥‚Äãt1‚àíe‚àíŒ≥‚Äãt)


(34)




Z‚Äã(t)=M1‚àíe‚àíŒ≥‚Äãt


(35)

Now consider a process in which each element of the vector of N discrete variables X undergoes the dynamics described by Eq. (25) independently. In that case, the differential equation describing the dynamics of the joint distribution Qt is,


d‚ÄãQtd‚Äãt=‚àëk=1N(I1‚äó‚ãØ‚äó‚Ñík‚äó‚Ä¶‚ÄãIN)‚ÄãQt


(36)

where Ij indicates the identity operator and ‚Ñíj the operator from Eq. (26) acting on the subspace of the jth discrete variable.
The Kronecker product of the matrix exponentials gives the time-evolution of the joint distribution,


e‚Ñí‚Äãt=‚®Çk=1Ne‚Ñík‚Äãt


(37)

with the matrix elements,


e‚Ñí‚Äãt‚Äã[j,i]=‚àèk=1Ne‚Ñík‚Äãt‚Äã[jk,ik]


(38)

where j and i are now vectors with N elements, indexed as ik or jk respectively.
Using Eqs. (33) - (35), we can find an exponential form for the joint process transition kernel (as defined in Eq. (21)),


Qt|0‚Äã(x‚Ä≤|x)=1Z‚Äã(t)‚Äãexp‚Å°(‚àëk=1NŒìk‚Äã(t)‚ÄãŒ¥x‚Ä≤‚Äã[k],x‚Äã[k])


(39)




Z‚Äã(t)=‚àèk=1NZk‚Äã(t)


(40)

Œìk‚Äã(t) and Zk‚Äã(t) are as given in Eqs. (34) and (35), with each dimension potentially having it‚Äôs own transition rate Œ≥k and number of categories Mk.
A.2Reverse Processes
In general, a random process for some variable X can be reversed using Bayes‚Äô rule,


Qt|t+Œî‚Äãt‚Äã(x‚Ä≤|x)=Qt+Œî‚Äãt|t‚Äã(x|x‚Ä≤)‚ÄãQt‚Äã(x‚Ä≤)Qt+Œî‚Äãt‚Äã(x)


(41)

where the conditionals are as defined in Eq. (21), and the marginals are,


Qt‚Äã(x)=‚Ñô‚Äã(X‚Äã(t)=x)


(42)

A differential equation that describes the reverse process can be found by analyzing Eq. (41) in the infinitesimal time limit. Specifically, defining a reversed time t=T‚àís given some arbitrary endpoint T and expanding Eq. (41) in Œî‚Äãs,


QT‚àís|T‚àí(s‚àíŒî‚Äãs)‚Äã(x‚Ä≤|x)‚âàŒ¥x,x‚Ä≤+Œî‚Äãs‚Äã‚Ñírev‚Äã(x‚Ä≤,x)


(43)

where ‚Ñírev is the generator of the reverse process,


‚Ñírev‚Äã(x‚Ä≤,x)=QT‚àís‚Äã(x‚Ä≤)QT‚àís‚Äã(x)‚ÄãlimŒî‚Äãs‚Üí0[dd‚ÄãŒî‚Äãs‚ÄãQT‚àí(s‚àíŒî‚Äãs)|T‚àís‚Äã(x|x‚Ä≤)]+Œ¥x,x‚Ä≤‚Äã(1QT‚àís‚Äã(x)‚Äãd‚ÄãQT‚àís‚Äã(x)d‚Äãs)


(44)

here, Œ¥x,x‚Ä≤ is used to indicate the Dirac delta function in the continuous case and the Kronecker delta in the discrete case.
If the dynamics of Q are linear and generated by ‚Ñí like Eq. (25), we can simplify,


limŒî‚Äãs‚Üí0[dd‚ÄãŒî‚Äãs‚ÄãQT‚àí(s‚àíŒî‚Äãs)|T‚àís‚Äã(x|x‚Ä≤)]=‚Ñí‚Äã(x,x‚Ä≤)


(45)

In this case, we can re-write Eq. (44) in the operator form,


‚Ñírev=Q‚Äã‚Ñí‚Ä†‚ÄãQ‚àí1+Q‚àí1‚Äãd‚ÄãQd‚Äãs


(46)

where ‚Ñí‚Ä† is the adjoint operator to ‚Ñí. For continuous variables, the adjoint operator is defined as,


‚à´œà2‚Äã‚Ñí‚Äãœà1‚Äãùëëx=‚à´œà1‚Äã‚Ñí‚Ä†‚Äãœà2‚Äãùëëx


(47)

for any test functions œà1 and œà2. For discrete variables, ‚Ñí‚Ä†=‚ÑíT.
A.2.1Continuous variables
In the case that the forward process is an It√¥ diffusion, ‚Ñí is the generator for the corresponding Fokker-Planck equation,


‚Ñí=‚àí‚àëi‚àÇ‚àÇxi‚Äãfi‚Äã(x,t)+12‚Äã‚àëi,j‚àÇ‚àÇxi‚Äã‚àÇ‚àÇxj‚ÄãDi‚Äãj‚Äã(t)


(48)

where D is a symmetric matrix, Di‚Äãj=Dj‚Äãi that does not depend on x.
Using Eq. (47) and integration by parts, it can be shown that the adjoint operator is,


‚Ñí‚Ä†=‚àëifi‚Äã‚àÇ‚àÇxi+12‚Äã‚àëi,jDi‚Äãj‚Äã‚àÇ‚àÇxi‚Äã‚àÇ‚àÇxi


(49)

By directly substituting Eq. (49) into Eq. (46) and simplifying, ‚Ñírev can be reduced to,


‚Ñírev=‚àëi‚àÇ‚àÇxi‚Äãgi+12‚Äã‚àëi,j‚àÇ‚àÇxi‚Äã‚àÇ‚àÇxj‚ÄãDi‚Äãj


(50)

with the drift vector g,


gi‚Äã(x,t)=fi‚Äã(x,t)‚àí1Qt‚Äã(x)‚Äã‚àëj‚àÇ‚àÇxj‚Äã[Di‚Äãj‚Äã(x,t)‚ÄãQt‚Äã(x)]


(51)

If Œî‚Äãt is chosen to be sufficiently small, Eq. (51) can be linearized and the transition kernel is Gaussian,


Qt|t+Œî‚Äãt‚Äã(x‚Ä≤|x)‚àùexp‚Å°(‚àí12‚Äã(x‚àíŒº)T‚ÄãŒ£‚àí1‚Äã(x‚àíŒº))


(52)




Œº=x+Œî‚Äãt‚Äãgi‚Äã(x,t)


(53)




Œ£=Œî‚Äãt‚ÄãD‚Äã(t)


(54)

Therefore, one can build a continuous diffusion model with arbitrary approximation power by working in the small Œî‚Äãt limit and approximating the reverse process using a Gaussian distribution with a neural network defining the mean vector [13, 4].
A.2.2Discrete variables
In a discrete diffusion model, ‚Ñí is given by Eq. (36). This tensor product form for ‚Ñí guarantees that ‚Ñí‚Äã(x‚Ä≤,x)=0 for any vectors x‚Ä≤ and x that have a Hamming distance greater than one (which means they have at least N‚àí1 matching elements). As such, in discrete diffusion models, neural networks trained to approximate ratios of the data distribution QT‚àís‚Äã(x‚Ä≤)QT‚àís‚Äã(x) for neighboring x‚Ä≤ and x can be used to implement an arbitrarily good approximation to the actual reverse process [7].
A.3The Diffusion Loss
As discussed in the main text, a diffusion model is trained by minimizing the distributional distance between the joint distributions of the forward process Q0,‚Ä¶,T and our learned approximation to the reverse process P0,‚Ä¶,TŒ∏,


‚ÑíD‚ÄãN(Œ∏)=D(Q0,‚Ä¶,T(‚ãÖ)||P0,‚Ä¶,TŒ∏(‚ãÖ))


(55)

the Markovian nature of Q can be taken advantage of to simplify Eq. (55) into a layerwise form,


‚ÑíD‚ÄãN(Œ∏)+C=‚àí‚àët=1TùîºQ‚Äã(xt‚àí1,xt)[log(PŒ∏(xt‚àí1|xt)]


(56)

where C does not depend on Œ∏. For denoising algorithms that operate in the infinitesimal limit, the simple form of PŒ∏ allows for ‚ÑíD‚ÄãN and its gradients to be computed exactly.
A.3.1A Monte-Carlo gradient estimator
In the case where PŒ∏‚Äã(xt‚àí1|xt) is an EBM, there exists no simple closed-form expression for ‚àáŒ∏‚ÑíD‚ÄãN‚Äã(Œ∏). In that case, one must employ a Monte Carlo estimator to approximate the gradient. This estimator can be derived directly by taking the gradient of Eq. (56),


‚àáŒ∏‚ÑíD‚ÄãN‚Äã(Œ∏)=‚àí‚àët=1TùîºQ‚Äã(xt‚àí1,xt)‚Äã[‚àáŒ∏log‚Å°(PŒ∏‚Äã(xt‚àí1|xt))]


(57)

If we have an EBM parameterization for PŒ∏‚Äã(xt‚àí1|xt) this may be simplified further. Specifically, given the latent variable from Eq. 8 in the main text, the gradient of log-likelihood may be simplified to,


‚àáŒ∏log‚Å°(PŒ∏‚Äã(xt‚àí1|xt))=ùîºPŒ∏‚Äã(xt‚àí1,zt‚àí1|xt)‚Äã[‚àáŒ∏‚Ñ∞t‚àí1m]‚àíùîºPŒ∏‚Äã(zt‚àí1|xt‚àí1,xt)‚Äã[‚àáŒ∏‚Ñ∞t‚àí1m]


(58)

Inserting this into Eq. (57) yields the final result given in Eq. 14 in the article.
A.4Simplification of the Energy Landscape
As the forward process timestep is made smaller, the energy landscape of the EBM-based approximation to the reverse process becomes simpler. A simple 1D example serves as a good demonstration of this concept. Consider the marginal energy function,


‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1)=(xt‚àí12‚àí1)2


(59)

and a forward process energy function that corresponds to Gaussian diffusion (Eq. (20)),


‚Ñ∞t‚àí1f‚Äã(xt‚àí1,xt)=Œª‚Äã(xt‚àí1xt‚àí1)2


(60)

The parameter Œª scales inversely with the size of the forward process timestep; that is, limŒî‚Äãt‚Üí0Œª=‚àû.
The reverse process conditional energy landscape is then ‚Ñ∞t‚àí1Œ∏+‚Ñ∞t‚àí1f. The effect of Œª on this is shown in Fig. 7.
Figure 7:Conditioning of the energy landscape As Œª is increased, the energy landscape is reshaped from a strongly bimodal distribution towards a simple Gaussian centered at xt=‚àí0.5. The latter is much easier to sample from.
The energy landscape is bimodal at Œª=0 and gradually becomes distorted towards an unimodal distribution centered at xt as Œª increases. This reshaping is intuitive, as shortening the forward process timestep should more strongly constrain xt‚àí1 to xt.
A.5Conditional Generation
The denoising framework can be adapted for conditional generation tasks, such as generating MNIST digits given a specific class label. In principle, this is very simple: we concatenate the target (in our case, the images) and a one-hot encoding of the labels into a contiguous binary vector and treat that whole thing as our training data on which we train the denoising model as described above.
In this case, the visible nodes of the Boltzmann machine are partitioned into "pixel nodes" VX and "label nodes" VL. All visible nodes come in pairs of input and output nodes (drawn in blue and green resp. in Fig. 3 in the main paper body and Fig. 9 below), so the set of visible nodes now consists of VXin,VXout,VLin, and VLout.
The training procedure works the same way as before, just using this label-augmented data. We obtain the noised training images Xn and labels Ln by noising each entry of X0 and L0 resp. independently using the forward process described in subsection A.1.2. Then we train the nth step model PŒ∏n(VXout=x,VLout=l|VXin=x‚Ä≤,VLin=l‚Ä≤) to approximate (in terms Kullback-Leibler divergence) the distribution ‚Ñô(Xn=x,Ln=l|Xn+1=x‚Ä≤,Ln+1=l‚Ä≤).
At inference time, we have two cases:
‚Ä¢ Unconditional inference proceeds as with regular denoising. We pass the pixel and label values backward through all the step models, and at the end, we record the pixel values.
‚Ä¢ For conditional generation we clamp all label output nodes VLout in all step models to l0 and sample X^n‚àºPŒ∏n(VXout=‚ãÖ|VXin=X^n+1,VLout=VLin=l0), where l0 is an unnoised label and X^n+1 is the output of PŒ∏n+1 (or uniform noise if n=N).
Note that all step models except Œ∏0 will be trained on somewhat noised labels, so they might never have seen a pristine unnoised label during training (if there are 10 classes and five label repetitions, a strongly noised label has an approximately 10√ó2‚àí50 chance of being a valid unnoised label). However, during conditional inference, the models will have their label nodes clamped to an unnoised label l0, and they may not know how this should influence the generated image (and this problem would only be exacerbated if we clamped to a noised label instead).
This issue can be mitigated by using a rate Œ≥X when noising image entries in the training data and a different rate Œ≥L for noising label entries. Recall that the higher the Œ≥, the noisier the data will become as n increases.
We consider two extremes:
‚Ä¢ If Œ≥L‚â•Œ≥X, then we have the exact same problem as before.
‚Ä¢ If Œ≥L=0, then the labels in the training data are a zero-temperature distribution. This low temperature can lead to freezing, potentially negating the benefits denoising could otherwise bring.
Experimentally, we observed that settings in the ranges Œ≥L‚àà[0.1,0.3] and Œ≥X‚àà[0.7,1.5] (for models with four to 12 steps) yielded good conditional generation performance while avoiding the freezing problem.
A.6Learning the marginal
If a DTM is trained to match the conditional distribution of the reverse process perfectly, the learned energy function ‚Ñ∞t‚àí1Œ∏ is the energy function of the true marginal distribution, that is, ‚Ñ∞t‚àí1Œ∏‚Äã(x)‚àùlog‚Å°Q‚Äã(xt‚àí1). To show this, we start by applying the Bayes‚Äô rule to the learned reverse process conditional in the limit that it perfectly matches the true reverse process,


Q‚Äã(xt|xt‚àí1)‚ÄãQ‚Äã(xt‚àí1)Q‚Äã(xt)=1Z‚Äã(Œ∏,xt)‚Äãe‚àí(‚Ñ∞t‚àí1f‚Äã(xt‚àí1,xt)+‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,Œ∏))


(61)

defining the distribution,


H‚Äã(xt‚àí1)=1Z‚Äã(Œ∏)‚Äã‚àëzt‚àí1e‚àí‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,zt‚àí1,Œ∏)


(62)




Z‚Äã(Œ∏)=‚àëxt‚àí1,zt‚àí1e‚àí‚Ñ∞t‚àí1Œ∏‚Äã(xt‚àí1,zt‚àí1,Œ∏)


(63)

extracting the forward process from the RHS of Eq. (61) and using Eq. (62),


Q‚Äã(xt‚àí1)Q‚Äã(xt)=Z‚Äã(Œ∏)‚ÄãZZ‚Äã(Œ∏,xt)‚ÄãH‚Äã(xt‚àí1)


(64)

Eq. (64) can easily be re-arranged into a form where the LHS depends only on xt, and the RHS depends only on xt‚àí1. From this, we can deduce,


Q‚Äã(xt‚àí1)H‚Äã(xt‚àí1)=c


(65)

from the fact that Q and H are both normalized, we can find that c=1, which establishes the desired equivalence.
Appendix BHardware accelerators for EBMs
In this work, we focus on a hardware architecture for EBMs that are naturally expressed as Probabilistic Graphical Models (PGMs). In a PGM-EBM, the random variables involved in the model map to the nodes of a graph, which are connected by edges that indicate dependence between variables.
PGMs form a natural basis for a hardware architecture because they can be sampled using a modular procedure that respects the graph‚Äôs structure. Specifically, the state of a PGM can be updated by iteratively stepping through each node of the graph and resampling one variable at a time, using only information about the current node and its immediate neighbors. Therefore, if a PGM is local, sparse, and somewhat heterogeneous, a piece of hardware can be built to efficiently sample from it that involves spatially arraying probabilistic sampling circuits that interact with each other cheaply via short wires.
This local PGM sampler represents a type of compute-in-memory approach, where the state of the sampling program is spatially distributed throughout the array of sampling circuitry. Since the sampling circuits only communicate locally, this type of computer will spend significantly less energy on communication than one built on a Von-Neumann-like architecture, which constantly shuttles data between compute and memory.
Formally, the algorithm that defines this modular sampling procedure for PGMs is called Gibbs sampling. In Gibbs sampling, samples are drawn from the joint distribution p‚Äã(x1,x2,‚Ä¶,xN) by iteratively updating the state of each node conditioned on the current state of its neighbors. For the it‚Äãh node, this means sampling from the distribution,


xi‚Äã[t+1]‚àºp‚Äã(xi|n‚Äãb‚Äã(xi)‚Äã[t]).


(66)

This procedure defines a Markov chain whose stationary distribution can be easily controlled by adjusting the conditional update distributions of each node (see the next section for an example). Starting from some random initialization, this iterative update must be applied potentially many times to all graph nodes before the Markov chain converges to the desired stationary distribution, allowing us to draw samples from it.
Figure 8:Chromatic Gibbs Sampling A schematic view of an abstract hardware accelerator for a simple EBM. Each of the model‚Äôs variables is assigned to a node. Each node is capable of receiving information from its neighbors and updating its state according to the appropriate conditional distribution. Since each node‚Äôs update distribution only depends on the state of its neighbors and because nodes of the same color do not neighbor each other, they can all be updated in parallel.
Gibbs sampling allows for any two nodes that are not neighbors to be updated in parallel, meaning that the state can be updated in batches corresponding to different color groups of the graph. For a more thorough explanation of how Gibbs sampling works, see  [8].
Fig. 8 shows a simple example of a PGM with two color groups that would be amenable to Gibbs sampling. Since x1 is only connected to x2 and x4, the update rule from Eq. (66) would take the form,


x1‚Äã[t+1]‚àºp‚Äã(x1|x4‚Äã[t],x2‚Äã[t])


(67)

If the joint distribution had sufficient structure such that the conditional for each node had the same form, a piece of hardware could be built to sample from this PGM by building a 3x3 grid of sampling circuits that communicate only with their immediate neighbors.
B.1Quadratic EBMs
The primary constraint around building a hardware device that implements Gibbs sampling is that the conditional update given in Eq. (66) must be efficiently implementable. Generally, this means that one wants it to take a form that is "natural" to the hardware substrate being used to build the computer.
To satisfy this constraint, it is generally necessary to limit the types of joint distributions that a hardware device can sample from. An example of such a restricted family of distributions is quadratic EBMs.
Quadratic EBMs have energy functions that are quadratic in the model‚Äôs variables, which generally leads to conditional updates computed by biasing a simple sampling circuit (Bernoulli, categorical, Gaussian, etc.) with the output of a linear function of the neighbor states and the model parameters. These simple interactions are efficient to implement in various types of hardware. As such, Quadratic EBMs have been the focus of most work on hardware accelerators for Gibbs sampling to date.
In the main text, we discuss Boltzmann machines, which involve only binary random variables and are the most basic form of quadratic EBM. The Conditional Update for Boltzmann Machines requires biasing a Bernoulli random variable according to a sigmoid function of a linear combination of the model parameters and the binary neighbor states, as shown in the main text, Eq. 11. This conditional update is efficiently implementable using an RNG with a sigmoidal bias and resistors, as discussed in section J.
Here, we will touch on a few other types of quadratic EBM that are more general. Although the experiments in this paper focused on Boltzmann machines, they could be trivially extended to these more expressive classes of distributions.
B.1.1Potts models
Potts models generalize the concept of Boltzmann machines to k-state variables. They have the energy function,


E‚Äã(x)=‚àëi,j=1N‚àëm,n=1Mxmi‚ÄãJm‚Äãni‚Äãj‚Äãxnj+‚àëi=1N‚àëm=1Mhmi‚Äãxmi


(68)




Jm‚Äãni‚Äãi=0


(69)

xmi is a one-hot encoding of the state of variable xi,


xmi‚àà{0,1}


(70)




‚àëmxmi=1


(71)

which implies that xmi=1 for a single value of m, and is zero otherwise. The distribution of any individual variable conditioned on it‚Äôs Markov blanket is,


p‚Äã(xmi=1|mb‚Äã(xi))=1Z‚Äãexp‚Å°(‚àíŒ≤‚Äã(‚àëj‚ààmb‚Äã(xi),nJm‚Äãni‚Äãj‚Äãxnj+‚àëj‚ààmb‚Äã(xi),nxnj‚ÄãJn‚Äãmj‚Äãi+hmi))


(72)

In the case that J has the symmetry,


Jm‚Äãni‚Äãj=Jn‚Äãmj‚Äãi


(73)

this reduces to,


p‚Äã(xmi=1|mb‚Äã(xi))‚àù1Z‚Äãe‚àíŒ∏mi


(74)




Œ∏mi=Œ≤‚Äã(2‚Äã‚àëj‚ààmb‚Äã(xi),nJm‚Äãni‚Äãj‚Äãxnj+hmi)


(75)

The parameters Œ∏ are defined to make it clear that this is a softmax distribution.
Therefore, to build a hardware device that samples from Potts models using Gibbs sampling, one would have to build a softmax sampling circuit parameterized by a linear function of the model weights and neighbor states. Potts model sampling is slightly more complicated than Boltzmann machine sampling, but it is likely possible.
B.1.2Gaussian-Bernoulli EBMs
Gaussian-Bernoulli EBMs extend Boltzmann machines to continuous, binary mixtures. In general, this type of model can have continuous-continuous, binary-binary, and binary-continuous interactions. For simplicity, if we consider only binary-continuous interactions, the energy function may be written as,


E‚Äã(v,h)=‚àëi=1Nv(vi‚àíbi)22‚ÄãœÉi2‚àí‚àëi=1Nv‚àëj=1Nhvi‚ÄãWi‚Äãj‚ÄãhjœÉi2‚àí‚àëj=1Nhcj‚Äãhj,


(76)

where vi‚àà‚Ñù are continuous variables with biases bi and variances œÉi2, hj‚àà{‚àí1,1} are binary variables with biases cj, and Wi‚Äãj are interaction weights.
Due to the structure of the energy function, the update rule for the continuous variables corresponds to drawing a sample from a Gaussian distribution with a mean that is a linear function of the neighbor states,


p(vi|mb(vi))=ùí©(Œºi,œÉi2/Œ≤),Œºi=bi+œÉi2‚àëj‚ààmb‚Äã(vi)Wi‚Äãjhj.


(77)

The binary update rule is similar to the rule for Boltzmann machines,


p(hj=1|mb(hj))=œÉ(2Œ≤(‚àëi‚ààmb‚Äã(hj)vi‚ÄãWi‚ÄãjœÉi2+cj))


(78)

Hardware implementations of Gaussian-Bernoulli EBMs are more difficult than the strictly discrete models because the signals being passed during conditional sampling of the binary variables are continuous. To pass these continuous values, they must either be embedded into several discrete variables or an analog signaling system must be used. Both of these solutions would incur significant overhead compared to the purely discrete models.
Appendix CA hardware architecture for denoising
The denoising models used in this work exclusively modeled distributions of binary variables. The reverse process energy function (Eq. 7 in the main text) was implemented using a Boltzmann machine. The forward process energy function ‚Ñ∞t‚àí1f was implemented using a simple set of pairwise couplings between xt (blue nodes) and xt‚àí1 (green nodes). The marginal energy function ‚Ñ∞t‚àí1Œ∏ was implemented using a latent variable model (latent nodes are drawn in orange) with a sparse, local coupling structure.
C.1Implementation of the forward process energy function
Figure 9:Our hardware denoising architecture (a) An example of a possible connectivity pattern as specified in Table. 1. For clarity, the pattern is illustrated as applied to a single cell; however, in reality, the pattern is repeated for every cell in the grid. (b) A graph for hardware denoising. The grid is subdivided at random into visible (green) nodes, representing the variables xt‚àí1, and latent (orange) nodes, representing zt‚àí1. Each visible node xjt‚àí1 is coupled to a (blue) node carrying the value from the previous step of denoising xjt (note that these blue nodes stay fixed throughout the Gibbs sampling).
From the exponential form of the discrete-variable forward process transition kernel given in Eq. (39), it is straightforward to derive a Boltzmann machine-style energy function that implements the forward process,


‚Ñ∞t‚àí1f=‚àëiŒìi‚Äã(t)2‚Äãxit‚Äãxit‚àí1


(79)

where xt‚Äã[i]‚àà{‚àí1,1} indicates the it‚Äãh element of the vector of random variables xt as usual.
C.2Implementation of the marginal energy function
We use a Boltzmann machine based on a grid graph to implement the marginal energy function. Our grids have both nearest-neighbor and long-range skip connections. A simple example of this is shown in Fig. 9 (a). This connectivity pattern is tiled such that every node in the bulk of the grid has the same connectivity to its neighbors. At the boundaries, connections that extend beyond the grid‚Äôs edges are not formed.
Within the grid, we randomly choose some subset of the nodes to represent the data variables xt‚àí1. The remaining nodes then implement the latent variable zt‚àí1. The grid is, therefore, a deep Boltzmann machine with a sparse connectivity structure and multiple hidden layers.
We use a particular set of connectivity patterns in the experiments in this article, which are specified in Table. 1. We say that node (x,y) has a connection rule of the form (a,b) if it is connected to nodes at positions (x+a,y+b),(x‚àíb,y+a),(x‚àía,y‚àíb),(x+b,y‚àía), so each connection rule adds up to 4 edges from this node.
Pattern
Connectivity
G8
(0,1),(4,1)
G12
(0,1),(4,1),(9,10)
G16
(0,1),(4,1),(8,7),(14,9)
G20
(0,1),(4,1),(3,6),(8,7),(14,9)
G24
(0,1),(1,2),(4,1),(3,6),(8,7),(14,9)

Table 1:Edges (ordered pairs) associated with graphs of various degrees.
As explicitly stated in Eq. 7 of the article, our variational approximation to the reverse process conditional has an energy function that is the sum of the forward process energy function and the marginal energy function. Physically, this corresponds to adding nodes to our grid that implement xt, which are connected pairwise to the data nodes implementing xt‚àí1 via the coupling defined in Eq. (79). This connectivity is shown in Fig. 9 (b).
Appendix DEnergetic analysis of the hardware architecture
Our RNG design uses only transistors and can integrate tightly with other traditional circuit components on a chip to implement a large-scale sampling system. Since there are no exotic components involved that introduce unknown integration barriers, it is straightforward to build a simple physical model to predict how this device utilizes energy.
The performance of the device can be understood by analyzing the unit sampling cell that lives on each node of the PGM implemented by the hardware. The function of this cell is to implement the Boltzmann machine conditional update, as given in Eq. 11 in the main text.
There are many possible designs for the sampling cell. The design considered here utilizes a linear analog circuit to combine the neighboring states and model weights, producing a control voltage for an RNG. This RNG then produces a random bit that is biased by a sigmoidal function of the control voltage. This updated state is then broadcast back to the neighbors. The cell must also support initialization and readout (get/set state operations). A schematic of a unit cell is shown in Fig. 8.
We provide experimental measurements of our novel RNG circuitry in the main text, which establish that random bits can be produced at a rate of œÑr‚Äãn‚Äãg‚àí1‚âà‚ÄÖ10‚ÄãMHz using ‚àº350‚ÄãaJ of energy per bit. Fig. 15 (a) shows an output voltage waveform from the RNG circuit. It wanders randomly between high and low states. Critically, the bias of the RNG circuit (the probability of finding it in the high or low state) is a sigmoidal function of its control voltage, which allows for a straightforward implementation of the conditional update using linear circuitry.
Figure 10:A schematic of a possible Boltzmann machine sampling cell A linear resistor network computes a biasing voltage given the sign-corrected neighbor states yn=xn‚äïsn. The output of this circuit biases an RNG that responds in a sigmoidal manner. This RNG processes freely when the clock is low and latches to a state when the clock is high. Upon the clock going high, the sampled state is broadcasted to the neighbors of the cell over wires.
The size of the RNG circuit can be used to anchor the dimensions of a future large-scale Gibbs sampling device. As shown in Fig. 15 (b), the RNG itself involves around 10 transistors and takes up ‚àº‚ÄÖ3‚ÄãŒº‚Äãm√ó3‚ÄãŒº‚Äãm on the die. It is reasonable to imagine that the whole sampling cell could fit in 4√ó this area and have a side length of 6‚ÄãŒº‚Äãm. Given this area, a 1000√ó1000 grid of sampling cells would fit within a 6‚Äãmm√ó6‚Äãmm chip.
Building on the measured characteristics of our RNG, we will now develop simple physical models for the remaining components of the sampling system. These models can then be combined to estimate the energy consumption of the diffusion models developed in this article running on our hardware.
D.1Biasing circuit
The multiply-accumulation of the model weights and neighbor states can be performed using a resistor network, as shown in Fig. 10. The dynamics of this resistor network are described by the differential equation,


‚àëj=1n+2Gj‚Äã(Vd‚Äãd‚Äãyj‚àíVb)=C‚Äãd‚ÄãVbd‚Äãt


(80)

where yi=xi‚äïsi is the XOR of the neighbor state xi with a sign bit si. There are n variable neighbor states and two fixed inputs (yn+1=1, yn+2=0), which are important for implementing the fixed bias term in the conditional update. Vd‚Äãd is the supply voltage and Vb is the output voltage that biases the RNG. Gi represents the conductance of the resistor corresponding to the it‚Äãh input. The capacitance C represents the parasitic capacitance to ground associated with any real implementation of this circuit and is critical to forming realistic estimates of speed and energy consumption. Realistic values for an implementation of this circuit in our transistor process are shown in Fig. 11 (a).
Since this equation is first order, the dynamics exponentially relax to some fixed point Vb‚àû,


Vb‚Äã(t)=c‚Äãe‚àít/œÑb‚Äãi‚Äãa‚Äãs+Vb‚àû


(81)

the time constant œÑb‚Äãi‚Äãa‚Äãs is,


œÑb‚Äãi‚Äãa‚Äãs=CGŒ£


(82)

and the fixed point is,


Vb‚àû=‚àëj=1n+2GjGŒ£‚ÄãVd‚Äãd‚Äãyj


(83)

where the total conductance GŒ£ is,


GŒ£=‚àëj=1n+2Gj


(84)

The RNG has a bias curve which takes the form,


‚Ñô‚Äã(xi=1)=œÉ‚Äã(VbVs‚àíœï)


(85)

inserting Eq. (83) and expanding the term inside the sigmoid,


VbVs‚àíœï=‚àëj=1nGjGŒ£‚ÄãVd‚ÄãdVs‚Äã(xj‚äïsj)+[Gn+1GŒ£‚ÄãVd‚ÄãdVs‚àíœï]


(86)

by comparison to the Boltzmann machine conditional, we can see that the first term implements the model weights (which can be positive or negative given an appropriate setting of the sign bit sj), and the second term implements a bias.
The static power drawn by this circuit can be written in the form,


P‚àû=CœÑb‚Äãi‚Äãa‚Äãs‚ÄãVd‚Äãd2‚Äã(1‚àíŒ≥)‚ÄãŒ≥


(87)

where 0‚â§Œ≥‚â§1 is the input-dependent constant,


Œ≥=‚àëj=1n+2GjGŒ£‚Äãyj


(88)

This fixed point must be held while the noise generator relaxes, which means that the energetic cost of the biasing circuit is approximately,


Eb‚Äãi‚Äãa‚Äãs‚âàP‚àû‚ÄãœÑr‚Äãn‚Äãg=C‚ÄãœÑr‚Äãn‚ÄãgœÑb‚Äãi‚Äãa‚Äãs‚ÄãVd‚Äãd2‚Äã(1‚àíŒ≥)‚ÄãŒ≥


(89)

This is maximized for Œ≥=12.
To avoid slowing down the sampling machine, œÑr‚Äãn‚ÄãgœÑb‚Äãi‚Äãa‚Äãs‚â´1. As such, ignoring the energy spent charging the capacitor ‚àº12‚ÄãC‚ÄãVb2 will not significantly affect the results, and the approximation made in Eq. (89) should be accurate. The energy consumed by the bias circuit is primarily due to static power dissipation.
D.2Local communication
Another significant source of energy consumption is the communication of state information between neighboring cells. In most electronic devices, signals are communicated by charging and discharging wires. Charging a wire requires the energy input,


Echarge=12‚ÄãCwire‚ÄãVsig2


(90)

where Cwire is the capacitance associated with the wire, which grows with its length, and Vsig is the signaling voltage level.
Figure 11:Parameters for the energy model (a) The parasitic capacitance associated with the output node of the biasing circuit for various numbers of neighbors. These capacitances were estimated using the PDK and a layout for a real transistor implementation of the biasing circuit. (b) The capacitance associated with routing wires of various lengths and geometry in our process, extracted using the PDK. (c) The energy required for a cell to signal to all of its neighbors as a function of signaling voltage for various connectivity patterns. This energy was calculated using the routing capacitance data from (b).
Given the connectivity patterns shown in table  1, it is possible to estimate the total capacitance Cn associated with the wire connecting a node to all of its neighbors,


Cn=4‚ÄãŒ∑‚Äã‚Ñì‚Äã‚àëiai2+bi2


(91)

where ‚Ñì‚âà6‚ÄãŒº‚Äãm is the sampling cell side length, and Œ∑‚âà350‚ÄãaF/Œº‚Äãm is the wire capacitance per unit length in our process, see Fig. 11 (b). ai and bi are the x and y components of the it‚Äãh connection rule, as described in section  C.C.2.
The charging energy Eq. (90) is plotted as a function of signaling voltage for various connectivity patterns in Fig. 11 (b).
D.3Global communication
Several systems on the chip require signals to be transmitted from some central location out to the individual sampling cells. This communication involves sending signals over long wires with a large capacitance, which is energetically expensive. Here, the cost of this global communication will be taken into consideration.
D.3.1Clocking
Although it is possible in principle to implement Gibbs sampling completely asynchronously, in practice, it is more efficient to implement standard chromatic Gibbs sampling with a global clock. A global clock requires a signal to be distributed from a central clock circuit to every sampling cell on the chip. This signal distribution is typically accomplished using a clock tree, a branching circuit designed to minimize timing inconsistencies between disparate circuit elements.
To simplify the analysis, we will consider a simple clock distribution scheme in which the clock is distributed by lines that run the entire length of each row in the grid. The total length of the wires used for clock distribution in this scheme is,


Lc‚Äãl‚Äão‚Äãc‚Äãk=N‚ÄãL


(92)

where N is the number of rows in the grid, and L is the length of a row. Given this length, the energetic cost of a clock pulse can be calculated using Eq. (90).
D.3.2Initialization and readout
A sampling program begins by initializing every sampling cell to a specific state and ends by reading out the state of a subset of the cells for use off-chip. Both of these operations require bits to be sent over a long wire of length L from the chip‚Äôs boundaries to a sampling cell in the bulk.
D.4Analysis of a complete sampling program
Given the above analysis of the various subsystems, it is straightforward to construct a model of the energy consumption of a complete denoising model. Running each layer of the denoising model requires initialization of all N nodes, chromatic Gibbs sampling for K iterations, and finally, readout of the Ndata data nodes,


E=T‚Äã(Esamp+Einit+Eread)


(93)

Esamp is the cost associated with the sampling iterations for each layer,


Esamp=K‚ÄãN‚Äã(Erng+Ebias+Eclock+Enb)


(94)

where Eclock and Enb are the per-cell costs associated with clock distribution and neighbor communication, respectively.
Einit is the cost of initializing all the cells at the beginning of the program,


Einit=N‚Äã12‚ÄãŒ∑‚ÄãL‚ÄãVs‚Äãi‚Äãg2


(95)

and Eread is the cost of reading out the data cells at the end,


Eread=Ndata‚Äã12‚ÄãŒ∑‚ÄãL‚ÄãVs‚Äãi‚Äãg2


(96)

This model was used to estimate the energy consumption of the denoising model depicted in Fig. 1 of the article. The mixing behavior for each layer in this denoising model is shown in Fig. 12 (a). All of the layers mix in tens of iterations, with the first layer decaying the most slowly. For the sake of energy calculations, we used K=250 for all layers to be conservative. Fig. 13 shows that for our trained denoising models, sampling for more than K‚âà250 steps brings almost no additional benefit, which supports our use of this number for energy calculation. This grid used for each EBM in this model consisted of N=4900 nodes that were connected using a G12 pattern. Ndata=834 of the nodes were assigned to data, and the rest were latent.
Given realistic choices for the rest of the free parameters of the model, the energetic cost of this denoising model is estimated to be around 1.6‚ÄãT‚ÄãnJ. This is almost entirely dominated by Esamp, with Einit+Eread‚âà0.01‚ÄãT‚ÄãnJ. A breakdown of the various contributions to Esamp, along with more details about the used model parameters, is given in Fig. 12 (b).
Figure 12:(a) Autocorrelation curve of a denoising model composed of Boltzmann machines. Each line represents the autocorrelation of one of the Boltzmann machines that make up a fully trained denoising model.
(b) Breakdown of the energetic cost of running a sampling cell. Here, we take œÑr‚Äãn‚Äãg/œÑb‚Äãi‚Äãa‚Äãs=15 and Œ≥=1/2. We also assume that signaling to neighbors is conducted at a voltage of 4‚ÄãVT (where VT is the thermal voltage kB‚ÄãT/e) and the clocking and read/write operations are conducted at a signal level of 5‚ÄãVT.
Figure 13:The quality of output images generated by our denoising models stops improving when we sample for more than K‚âà250 steps.
This exact procedure was used to estimate the energy consumption of the MEBMs in Fig. 1 in the article. In this case, T=1 and K were estimated from the autocorrelation data for each layer; see section  K.
D.5Level of realism
The model presented here captures all of the central functional units of a hardware Boltzmann machine sampler. However, the analysis was performed at a high level, and the model almost certainly underestimates the actual energy consumption of a complete device. In practice, when comparing the results of this type of calculation to a detailed analysis of a complete device design, we generally find agreement within an order of magnitude. Given that the gap between conventional methods and our novel hardware architecture is at least several orders of magnitude, this low-resolution analysis is useful, as it supports the claims made in this article without getting into every implementation detail.
Some of the discrepancies between the high-level and detailed model can be attributed to overheads associated with real circuits. A real implementation of the biasing circuit discussed in section  D.D.1 is more complicated than the theoretical model because tunable resistors do not exist. Communications with neighboring cells over long wires require driver circuits, which consume additional energy beyond what is spent charging the line. Despite this, real circuits are bound by the same fundamental physics as the simplified models presented here. As such, the simplified models tend to estimate energy consumption within a factor of two or three of real-life values.
A real device also has additional supporting circuitry compared to our stripped-down model. In the remainder of this section, we will discuss some examples of such supporting circuitry and argue that their contributions to energy consumption at the system level ought not to be significant.
D.5.1Programming the weights and biases
Section D.D.1 discusses a simple circuit that uses resistors to implement the multiply-accumulate required by the conditional update rule. Key to this is being able to tune the conductance of the resistors to implement specific sets of weights and biases (see Eq. (86)).
Practically, implementing this tunability requires that the model parameters be stored in memory somewhere on the chip. Writing to and maintaining these memories costs energy.
Writing to the memories uses much more energy than maintaining the state. However, if writes are infrequent (program the device once and then run many sampling programs on it before writing again), then the overall cost of the memory is dominated by maintenance. Luckily, most conventional memories are specifically designed to consume as little energy as possible when not being accessed. As such, in practice, the cost of memory maintenance is small compared to the other costs associated with the sampling cells and does not significantly change the outcome shown in Fig. 12.
D.5.2Off-chip communication
External devices have to communicate with our chip for it to be useful. The cost of this communication depends strongly on the tightness of integration between the two systems and is impossible to reason about at an abstract level. As such, the analysis of communication here (as in Section D.3.2) was limited to the cost of getting bits out to the edge of our chip, which is a lower bound on the actual cost.
However, we have found that a more detailed analysis, which includes the cost of communication between two chips mediated by a PCB, does not significantly change the results at the system level. The fundamental reason for this is that sampling programs for complex models run for many iterations before mixing and sending the results back to the outside world. This is reflected in the discrepancy between Esamp and Einit+Eread found in section D.D.4.
D.5.3Supporting circuitry
Any real chip has digital and analog supporting circuitry that provides basic functionality, such as clocking and communication, allowing the rest of the chip to function correctly. The fraction of the energy budget spent on this supporting circuitry generally depends on its size compared to the core computer. Due to the heterogeneity of our architecture, it is possible to share most of the supporting circuitry among many sampling cells, which dramatically reduces the per-cell cost. As such, the energy cost of the supporting circuitry is not significant at the system level.
Appendix EEnergy analysis of GPUs
All experiments shown in Fig. 1 in the article were conducted on NVIDIA A100 GPUs. The empirical estimates of energy were conducted by drawing a batch of samples from the model and measuring the GPU energy consumption and time via Zeus [14]. The theoretical energy estimates were derived by taking the number of model FLOPS (via JAX and PyTorch‚Äôs internal estimators) and plugging them into the NVIDIA GPU specifications (19.5 TFLOPS for Float32 and 400W). The empirical measurements are compared to theoretical estimates for the VAE in Table 2, and the empirical measurements show good alignment with the theoretical.
FID
Empirical Efficiency
Theoretical Efficiency
30.5
6.1√ó10‚àí5
2.3√ó10‚àí5
27.4
1.5√ó10‚àí4
0.4√ó10‚àí4
17.9
2.5√ó10‚àí3
1.7√ó10‚àí3

Table 2:Comparing theoretical vs empirical energy consumption for a VAE on a GPU. Energy efficiencies are reported in units of joules per sample.
The models were derived from available implementations and are based on ResNet [3] and UNet [11] style architectures. Their FID performance is consistent with published literature values [2, 1, 9]. The goal is not to achieve state of the art performance, but to represent the relative scales of energy consumption of the algorithms.
The reader may be surprised to see that the diffusion model is substantially less energy-efficient than the VAE given the relative dominance in image generation. However, two points should be kept in mind. First, while VAE remains a semi-competitive model for these smaller datasets, this quickly breaks down. On larger datasets, a FID performance gap usually exists between diffusion models and VAEs. Second, these diffusion models (based on the original DDPM [4]) have performance that can depend on the number of diffusion time steps. So, not only is the UNet model often larger than a VAE decoder, but it also must be run dozens to thousands of times in order to generate a single sample (thus resulting in multiple orders of magnitude more energy required). Modern improvements, such as distillation [liu2023instaflow], may move the diffusion model energy efficiency closer to the VAE‚Äôs.
Appendix FTotal correlation penalty
In the main text (see Eq. 17), we explain how we utilize a total correlation penalty to encourage the latent variable EBMs employed in our model to mix rapidly. Here, we will discuss a few details of this regularizer and the method we use to control its strength adaptively.
F.1Gradients of the total correlation penalty
The total correlation penalty is a convenient choice in this context because its gradients can be computed using the same samples used to estimate the gradient of the usual loss used in training, ‚àáŒ∏‚ÑíD‚ÄãN. Namely, treating the factorized distribution as a constant with respect to the gradient,


‚àáŒ∏‚ÑítT‚ÄãC=ùîºQ‚Äã(xt‚àí1)‚Äã[ùîºd‚Äã(st‚àí1|xt)‚Äã[‚àáŒ∏‚Ñ∞t‚àí1Œ∏]‚àíùîºPŒ∏(st‚àí1|xt))‚Äã[‚àáŒ∏‚Ñ∞t‚àí1Œ∏]]


(97)

where,


d‚Äã(st‚àí1|xt)=‚àèi=1MPŒ∏‚Äã(sit‚àí1|xt)


(98)

The second term in Eq. (97) also appears in the estimator for ‚àáŒ∏‚ÑíD‚ÄãN. The first term can be simplified when ‚Ñ∞t‚àí1Œ∏ has particular symmetries. For example, if ‚Ñ∞t‚àí1Œ∏ is a Boltzmann machine energy function (see main text Eq. 10),


ùîºd‚Äã(st‚àí1|xt)‚Äã[dd‚Äãhi‚Äã‚Ñ∞t‚àí1Œ∏]=‚àíŒ≤‚ÄãùîºPŒ∏‚Äã(si|xt)‚Äã[si]


(99)




ùîºd‚Äã(st‚àí1|xt)‚Äã[dd‚ÄãJi‚Äãj‚Äã‚Ñ∞t‚àí1Œ∏]=‚àíŒ≤‚ÄãùîºPŒ∏‚Äã(si|xt)‚Äã[si]‚ÄãùîºPŒ∏‚Äã(sj|xt)‚Äã[sj]


(100)

Each of these terms is easy to compute given the samples used to estimate ‚àáŒ∏‚ÑíD‚ÄãN.
F.2Low dimensional embedding of the data
For all experiments in this article, the embedding function f used in autocorrelation calculations was the encoding neural network used in FID computation. Using the encoder was an arbitrary choice, and we could have just as easily used a much simpler function. For example, we found that random linear projections y‚Äã[j]=A‚Äãx‚Äã[j] worked just as well as the neural network for autocorrelation calculations.
F.3Control of the penalty strength
The optimal strength of the correlation penalty Œªt may vary depending on the specific denoising step t (models for less noisy data near t=0 may require stronger regularization) and may even change during training for a single-step model. Manually tuning Œªt for each of the step-models would be prohibitively expensive.
To address this, we employ an Adaptive Correlation Penalty (ACP) scheme that dynamically adjusts Œªt based on an estimate of the model‚Äôs current mixing time. We use the autocorrelation of the Gibbs sampling chain, ry‚Äãyt, as a proxy for mixing, as described in Section H and the main text, Eq. 18.
Our ACP algorithm monitors the autocorrelation at a lag K equal to the number of Gibbs steps used in the estimation of ‚àáŒ∏‚ÑíD‚ÄãN. The goal is to adjust Œ≥CP to keep this autocorrelation below a predefined target threshold ŒµACP.
A simple layerwise procedure is used for this control. The inputs to the algorithm are the initial values of Œªt, a target autocorrelation threshold ŒµACP (e.g., 0.03), an update factor Œ¥ACP (e.g., 0.2) and a lower limit Œªtmin (e.g., 0.0001).
At the end of each training epoch m:
1. Estimate the current autocorrelation amt=ry‚Äãyt‚Äã[K]. This estimate can be done by running a longer Gibbs chain periodically and calculating the empirical autocorrelation from the samples.
2. Set Œªt‚Ä≤=m‚Äãa‚Äãx‚Äã(Œªtmin,Œªt(m)) to avoid getting stuck at 0.
3. Update Œªt for the next epoch (m+1) based on amt and the previous value am‚àí1t (if m>0):
‚Ä¢ If amt<ŒµACP: The chain mixes sufficiently fast; reduce the penalty slightly.


Œªt(m+1)‚Üê(1‚àíŒ¥ACP)‚ÄãŒªt‚Ä≤





‚Ä¢ Else if amt‚â•ŒµACP and amt‚â§am‚àí1t (or m=0): Mixing is slow but not worsening (or baseline); keep the penalty strength.


Œªt(m+1)‚ÜêŒªt‚Ä≤





‚Ä¢ Else (amt>ŒµACP and amt>am‚àí1t): Mixing is slow and worsening; increase the penalty.


Œªt(m+1)‚Üê(1+Œ¥ACP)‚ÄãŒªt‚Ä≤







4. If the proposed value Œªt(m+1)<Œªtmin, then set Œªt(m+1)‚Üê0.
Our experiments indicate that this simple feedback mechanism works effectively. While Œªt and the autocorrelation amt might exhibit some damped oscillations for several epochs before stabilizing this automated procedure is vastly more efficient than performing manual hyperparameter searches for Œªt for each of the T models.
Training is relatively insensitive to the exact choice of ŒµACP within a reasonable range (e.g., [0.02,0.1]) and Œ¥ACP (e.g., [0.1,0.3]). Assuming that over the course of training the Œªt parameter settles around some value Œªt‚àó, one should aim for the lower bound parameter Œªtmin to be smaller than 12‚ÄãŒªt‚àó, while making sure that the ramp-up time log‚Å°(Œªt‚àó)‚àílog‚Å°(Œªtmin)log‚Å°(1+Œ¥ACP) remains small. Settings of Œªtmin in the range [0.001,0.00001] all produced largely the same result, the only difference being that values on the lower end of that range led to a larger amplitude in oscillations of Œªt and amt, but training eventually settled for all values. An example of some ACP dynamics is shown in Fig. 14:
Training on Fashion-MNIST with the typical experimental setup, we observed nearly the same performance (a FID of 28¬±1) for all choices of ŒµACP, Œ¥ACP and Œªtmin in the ranges written above, so long as we trained for at least 100 epochs (with specific settings the training took longer to converge).
Figure 14:The active correlation penalty The dynamics of ry‚Äãyt and Œªt over a training run. Large values of ry‚Äãyt lead to increasingly large values of Œªt, which cause ry‚Äãyt to decrease. The system reaches a stable configuration by the end of training.
Appendix GEmbedding integers into Boltzmann machines
In some of our experiments, we needed to embed continuous data into binary variables. We chose to do this by representing a k-state categorical variable Xi using the sum k binary variables Zik,


Xi=‚àëk=1KiZi(k)


(101)

where Zi(k)‚àà{0,1}. These binary variables can be trivially converted into spin variables that are {‚àí1,1} valued using a linear change of variables.
Energy functions that involve quadratic interactions between these categorical variables can be reduced to Boltzmann machines with local patches of all-to-all connectivity. For example, consider the energy function,


E‚Äã(x;Œ∏)=‚àí‚àëi‚â†jwi‚Äãj‚ÄãXi‚ÄãXj‚àí‚àëi=1dbi‚ÄãXi


(102)

inserting Eq. (101), we can rewrite this in terms of quadratic interactions between the underlying spins Zi(k),


E‚Äã(z;Œ∏)=‚àí‚àëi‚â†jwi‚Äãj‚Äã(‚àëk=1KiZi(k))‚Äã(‚àël=1KjZj(l))‚àí‚àëibi‚Äã(‚àëk=1KiZi(k))


(103)

which is a standard Boltzmann machine energy function that can be run on our hardware, just like any other.
Appendix HThe autocorrelation function and mixing time
This section gives a brief derivation of how the Mixing time of a Markov chain can be estimated using its autocorrelation. Proofs of the properties noted here can be found in most standard textbooks on Markov chains, such as [6].
Suppose X is a discrete-time Markov chain on a finite state space {1,‚Ä¶,d}. Suppose its transition kernel is time-homogeneous and given by a matrix P=(px‚Äãy)1‚â§x,y‚â§d with entries px‚Äãy=‚Ñô‚Äã(Xt+1=y|Xt=x). Furthermore, assume the Markov chain is:
‚Ä¢ irreducible, i.e. it is possible to get from any starting node to any other node in a finite number of steps, and
‚Ä¢ aperiodic, i.e. for any starting position x‚àà{1,‚Ä¶,d}, there exists some T‚àà‚Ñï such that for all t‚â•T, ‚Ñô‚Äã(Xt=x|X0=x)>0.
Since this Markov chain is defined on a finite state space and is irreducible, there exists a unique stationary distribution œÄ=œÄ‚ÄãP. Furthermore, as a consequence of aperiodicity, for any starting distribution œà0, the distribution œàt of the Markov chain at time t converges to œÄ as t‚Üí‚àû, that is


œàt=œà0‚ÄãPt‚ÜíœÄ‚Äã as ‚Äãt‚Üí‚àû.



The transition matrix can be diagonalized as P=U‚àí1‚ÄãŒ£‚ÄãU, where Œ£ is a diagonal matrix and without loss of generality, we can assume that its entries are ordered 1=œÉ1>œÉ2‚â•‚Ä¶‚â•œÉd‚â•0. Then the tth power of P can be written as Pt=U‚àí1‚ÄãŒ£t‚ÄãU. We write U‚Äã(i,x) for the entry in the ith row and xth column of U (and likewise for U‚àí1). The first left eigenvector of P (and hence the first row of U) is the stationary distribution œÄ=œÄ‚ÄãP=U‚Äã(1,‚ãÖ). The first right eigenvector of P is a column of ones, that is U‚àí1‚Äã(‚ãÖ,1)=ùüè.
Let f:{1,‚Ä¶,d}‚Üí‚Ñù be any function and write,


Œº0f‚â°ùîºY‚àºœà0‚Äã[f‚Äã(Y)]=ùîº‚Äã[f‚Äã(X0)]


(104)

where œà0 is the initial distribution of the Markov chain X and,


Œº‚àûf‚â°ùîºY‚àºœÄ‚Äã[f‚Äã(Y)]=limt‚Üí‚àûùîº‚Äã[f‚Äã(Xt)]


(105)

Then, write Œ¥k for the column vector with a one at kth entry and zeros elsewhere. We can then compute,


ùîº‚Äã[f‚Äã(X0)‚Äãf‚Äã(Xt)]=‚àëx0=1df‚Äã(x0)‚Äã‚Ñô‚Äã[X0=x0]‚Äãùîº‚Äã[f‚Äã(Xt)|X0=x0]=‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚Äã(Œ¥x0T‚ÄãPt)‚Äã(x)=‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚Äã‚àëj=1dU‚àí1‚Äã(x0,j)‚ÄãœÉjt‚ÄãU‚Äã(j,x)=(‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚ÄãU‚àí1‚Äã(x0,1)‚ÄãœÉ1t‚ÄãU‚Äã(1,x))++‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚Äã‚àëj=2dU‚àí1‚Äã(x0,j)‚ÄãœÉjt‚ÄãU‚Äã(j,x)=(‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚ÄãœÄ‚Äã(x))+‚àëj=2dœÉjt‚Äã‚àëx0=1d‚àëx=1df‚Äã(x0)‚Äãf‚Äã(x)‚Äãœà0‚Äã(x0)‚ÄãU‚àí1‚Äã(x0,j)‚ÄãU‚Äã(j,x)=Œº0f‚ÄãŒº‚àûf+‚àëj=2dœÉjt‚Äãcj,


(106)

where cj are constants independent of t. Hence, if we can plot the quantity ùîºf‚Äã(X0)‚Äãf‚Äã(Xt)‚àíŒº0f‚ÄãŒº‚àûf for very large t, the contributions of the smaller eigenvalues become negligible relative to the contribution of œÉ2, allowing us to estimate the value of œÉ2.
Why does knowing œÉ2 help us compute the mixing time? Recall that the mixing time œÑ is defined as


œÑ‚Äã(Œµ)=min‚Å°{t‚â•0:maxœà0‚Å°‚Äñœà0‚ÄãPt‚àíœÄ‚ÄñTV‚â§Œµ},



‚ÄñŒº‚àíŒΩ‚ÄñTV=12‚Äã‚àëy‚ààùí≥|Œº‚Äã(y)‚àíŒΩ‚Äã(y)| denotes the total variation distance, and Œµ>0 is a prescribed tolerance.
We can rewrite the total variation distance in this definition as


‚Äñœà0‚ÄãPt‚àíœÄ‚ÄñTV
=12‚Äã‚àëx=1d|œÄ‚Äã(x)‚àí‚àëj=1d(œà0‚ãÖU‚àí1‚Äã(‚ãÖ,j))‚ÄãœÉjt‚ÄãU‚Äã(j,x)|
( ‚Äãœà0‚ãÖU‚àí1‚Äã(‚ãÖ,1)=1‚Äã and ‚ÄãU‚Äã(1,‚ãÖ)=œÄ‚Äã )






=12‚Äã‚àëx=1d|œÄ‚Äã(x)‚àíœÄ‚Äã(x)+‚àëj=2d(œà0‚ãÖU‚àí1‚Äã(‚ãÖ,j))‚ÄãœÉjt‚ÄãU‚Äã(j,x)|






‚â§12‚Äã‚àëx=1d‚àëj=2d|œà0‚ãÖU‚àí1‚Äã(‚ãÖ,j)|‚Äã|œÉjt|‚Äã|U‚Äã(j,x)|






=‚àëj=2dœÉjt‚Äãaj‚â§œÉ2t‚Äã‚àëj=2daj



where aj are some non-negative constants. Therefore, we can establish the following upper bound:


œÑ‚Äã(Œµ)‚â§log‚Å°(Œµ)‚àílog‚Å°(‚àëj=2daj)log‚Å°(œÉ2).



The smaller the value of œÉ2, the faster the mixing time.
Appendix IDeterministic embeddings for DTMs
In Section V of the paper, we mention hybrid thermodynamic models, the purpose of which is to combine the flexibility of classical neural networks (NNs) with the efficiency of probabilistic computers. For example, in the context of image generation, a small convolutional neural network can be used to map color images into a format compatible with a binary DTM. To properly take advantage of the DTM‚Äôs energy efficiency, the classical model should be at least 2 or 3 orders of magnitude smaller (e.g., in terms of parameter count or number of operations per sample) than the DTM.
There are various options for the type of classical model one can use for the embedding, e.g., invertible models such as GLOW [5] or Normalizing Flows [10], as well as simpler solutions, such as an Autoencoder.
For our proof-of-concept for hybrid models, we used a combination of an Autoencoder and a GAN [Goodfellow2014GAN].
‚Ä¢ First, we train a convolutional Autoencoder (encoder plus decoder) that maps images into a binary latent space (achieved through a combination of a sigmoid activation, a binarization penalty, and a straight-through gradient).
‚Ä¢ Second, we train a DTM on latent embeddings of the training images. At inference time, the samples generated by the DTM are passed through the decoder to produce images.
‚Ä¢ Thirdly, we use a GAN-like approach to fine-tune the decoder to utilize the outputs of the Boltzmann machine maximally. Specifically, the Boltzmann machine outputs are used as the noise source, which is fed into the decoder (now taking the role of the generator in the GAN architecture), and finally, a critic is trained to guide the decoder towards generating higher-quality images.
Our hybrid model achieved a FID score of ‚àº60 on CIFAR10. Our DTM had 8 million parameters, the decoder had 65k, and the encoder and critic were both below 500k parameters. At inference time, only the DTM and the decoder are used. To achieve a similar performance with a classical GAN, the decoder/generator requires about 500000 parameters.
Appendix JSome details on our RNG
Our RNG is a digitizing comparator fed by a source of Gaussian noise. The noise source is implemented using the circuitry and principles described in [our_gyrator]. The comparator is a standard design that operates in subthreshold to minimize energy consumption. The mean of the Gaussian noise is shifted before it is sent into the comparator to implement the bias control. A schematic of our RNG is shown in Fig. 15 (a).
Another example of an output voltage signal from our RNG is shown in Fig. 15 (b). The signal randomly wanders between high and low-voltage states. Suppose this signal is repeatedly observed, waiting for at least the correlation time of the circuit between observations. In that case, one will approximately draw samples from a Bernoulli distribution with a bias parameter that depends on the circuit‚Äôs control voltage.
Our RNG was part of the same test chip used to carry out the experiments in [our_gyrator]. The output of the RNG was fed into an amplification chain that buffered it and allowed its signal to be observed using an external oscilloscope. Fig. 15 (c) shows an image of our packaged test chip, along with a view of our RNG through a 100√ó microscope objective.
Figure 15:Our RNG. (a) A high-level schematic of our RNG design. (b) Stochastic voltage signal from our RNG. The high level represents one, and the low level represents 0. The signal wanders randomly between high and low levels, with the amount of time it spends in each level controlled by the bias voltage. (c) An image of our packaged test chip (with the top of the package removed) assembled onto a PCB. We also show an optical microscope image of several RNG circuits on our test chip. Each circuit occupies an approximately 3√ó3‚ÄãŒº‚Äãm area on the chip.
Appendix KMEBM experiments
Our experiments on MEBMs were conducted in the typical way [12]. We employed the same Boltzmann machine architecture as we typically use for the DTM layers, specifically L=70 with G12 connectivity. Random nodes were chosen to represent the data, and the rest were left as latent variables (as discussed in section C).
Generating the data presented in Figs. 1 and 2 in the main text required controlling the mixing time of a trained Boltzmann machine. To achieve this, we added a fixed correlation penalty (Eq. 17 in the main text) and varied the strength to control the allowed complexity of the energy landscape.
Fig. 16 (a) shows an example of the raw autocorrelation curves produced by sampling from Boltzmann machines trained with different correlation penalty strengths. The slowest exponential decay rate (œÉ2) could be estimated for most of the curves by fitting a line to the natural log of the autocorrelation curve at long times, see Fig. 16 (b) The two curves with the smallest correlation penalty did not reduce to simple exponential decay during the measured lag values, which means the decay rate was too long to be extracted from our data.
Figure 16:Boltzmann machine autocorrelation curves (a) The raw autocorrelation data associated with Boltzmann machines trained using different values of the parameter Œª. (b) The log of the long-time autocorrelation for some of the curves shown in (a). All curves, except for the blue and orange ones, eventually became linear.
The exponential decay rates extracted from Fig. 16 were used as the mixing times in Fig. 2 in the article. Calling this a "mixing time" is a slight abuse of nomenclature. However, we did not think it made enough of a difference to the article‚Äôs message to disambiguate (since it is an upper bound on the mixing time, as discussed in Section H).
References
[1]
C. Chadebec, L. Vincent, and S. Allassonniere (2022)Pythae: Unifying generative autoencoders in python-a benchmarking use case.Adv. Neural Inf. Process. Syst. 35, pp. 21575‚Äì21589.External Links: Document, LinkCited by: Appendix E.
[2]
B. Dai and D. Wipf (2019)Diagnosing and Enhancing VAE Models.In International Conference on Learning Representations,External Links: LinkCited by: Appendix E.
[3]
K. He, X. Zhang, S. Ren, and J. Sun (2016)Deep residual learning for image recognition.In Proceedings of the IEEE conference on computer vision and pattern recognition,pp. 770‚Äì778.External Links: Document, LinkCited by: Appendix E.
[4]
J. Ho, A. Jain, and P. Abbeel (2020)Denoising diffusion probabilistic models.Adv. Neural Inf. Process. Syst. 33, pp. 6840‚Äì6851.External Links: Document, LinkCited by: ¬ßA.2.1, Appendix E.
[5]
D. P. Kingma and P. Dhariwal (2018)Glow: Generative Flow with Invertible 1x1 Convolutions.In Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.),Vol. 31, pp. .External Links: LinkCited by: Appendix I.
[6]
D.A. Levin, Y. Peres, and E.L. Wilmer (2009)Markov Chains and Mixing Times.American Mathematical Soc..External Links: ISBN 9780821886274, LinkCited by: Appendix H.
[7]
A. Lou, C. Meng, and S. Ermon (2024)Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution.External Links: 2310.16834, LinkCited by: ¬ßA.2.2.
[8]
K. P. Murphy (2023)Probabilistic Machine Learning: Advanced Topics.MIT Press.External Links: LinkCited by: Appendix B.
[9]
P. Ostheimer, M. Nagda, M. Kloft, and S. Fellenz (2025)Sparse Data Generation Using Diffusion Models.arXiv preprint arXiv:2502.02448.External Links: Document, LinkCited by: Appendix E.
[10]
G. Papamakarios, E. Nalisnick, D. J. Rezende, S. Mohamed, and B. Lakshminarayanan (2021)Normalizing Flows for Probabilistic Modeling and Inference.J. Mach. Learn. Res. 22 (57), pp. 1‚Äì64.External Links: LinkCited by: Appendix I.
[11]
O. Ronneberger, P. Fischer, and T. Brox (2015)U-net: Convolutional networks for biomedical image segmentation.In Medical image computing and computer-assisted intervention‚ÄìMICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18,pp. 234‚Äì241.External Links: Document, LinkCited by: Appendix E.
[12]
M. M. H. Sajeeb, N. A. Aadit, S. Chowdhury, T. Wu, C. Smith, D. Chinmay, A. Raut, K. Y. Camsari, C. Delacour, and T. Srimani (2025-07)Scalable connectivity for ising machines: dense to sparse.Phys. Rev. Appl. 24, pp. 014005.External Links: Document, LinkCited by: Appendix K.
[13]
J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli (2015)Deep unsupervised learning using nonequilibrium thermodynamics.In International conference on machine learning,pp. 2256‚Äì2265.External Links: Document, LinkCited by: ¬ßA.2.1.
[14]
J. You, J. Chung, and M. Chowdhury (2023)Zeus: Understanding and optimizing {GPU} energy consumption of {DNN} training.In 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23),pp. 119‚Äì139.External Links: Document, LinkCited by: Appendix E.

